{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.2.2+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: /home/<username>/.conda/envs/unetSSL/lib/python3.11/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scipy version: 1.12.0\n",
      "Pillow version: 10.3.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.2.1\n",
      "einops version: 0.8.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn import L1Loss\n",
    "from monai.utils import set_determinism, first\n",
    "from monai.networks.nets import ViTAutoEnc\n",
    "from monai.losses import ContrastiveLoss\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.config import print_config\n",
    "from monai.transforms import (\n",
    "    LoadImaged,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    CopyItemsd,\n",
    "    SpatialPadd,\n",
    "    EnsureChannelFirstd,\n",
    "    Spacingd,\n",
    "    OneOf,\n",
    "    ScaleIntensityRanged,\n",
    "    RandSpatialCropSamplesd,\n",
    "    RandCoarseDropoutd,\n",
    "    RandCoarseShuffled,\n",
    ")\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image': './Synth3DValTrain/im0.nii.gz', 'label': './Synth3DValTrain/seg0.nii.gz'}, {'image': './Synth3DValTrain/im1.nii.gz', 'label': './Synth3DValTrain/seg1.nii.gz'}, {'image': './Synth3DValTrain/im2.nii.gz', 'label': './Synth3DValTrain/seg2.nii.gz'}, {'image': './Synth3DValTrain/im3.nii.gz', 'label': './Synth3DValTrain/seg3.nii.gz'}, {'image': './Synth3DValTrain/im4.nii.gz', 'label': './Synth3DValTrain/seg4.nii.gz'}, {'image': './Synth3DValTrain/im5.nii.gz', 'label': './Synth3DValTrain/seg5.nii.gz'}, {'image': './Synth3DValTrain/im6.nii.gz', 'label': './Synth3DValTrain/seg6.nii.gz'}, {'image': './Synth3DValTrain/im7.nii.gz', 'label': './Synth3DValTrain/seg7.nii.gz'}, {'image': './Synth3DValTrain/im8.nii.gz', 'label': './Synth3DValTrain/seg8.nii.gz'}, {'image': './Synth3DValTrain/im9.nii.gz', 'label': './Synth3DValTrain/seg9.nii.gz'}] [{'image': './Synth3DValTrain/im0.nii.gz', 'label': './Synth3DValTrain/seg0.nii.gz'}, {'image': './Synth3DValTrain/im1.nii.gz', 'label': './Synth3DValTrain/seg1.nii.gz'}, {'image': './Synth3DValTrain/im2.nii.gz', 'label': './Synth3DValTrain/seg2.nii.gz'}, {'image': './Synth3DValTrain/im3.nii.gz', 'label': './Synth3DValTrain/seg3.nii.gz'}, {'image': './Synth3DValTrain/im4.nii.gz', 'label': './Synth3DValTrain/seg4.nii.gz'}, {'image': './Synth3DValTrain/im5.nii.gz', 'label': './Synth3DValTrain/seg5.nii.gz'}, {'image': './Synth3DValTrain/im6.nii.gz', 'label': './Synth3DValTrain/seg6.nii.gz'}, {'image': './Synth3DValTrain/im7.nii.gz', 'label': './Synth3DValTrain/seg7.nii.gz'}, {'image': './Synth3DValTrain/im8.nii.gz', 'label': './Synth3DValTrain/seg8.nii.gz'}, {'image': './Synth3DValTrain/im9.nii.gz', 'label': './Synth3DValTrain/seg9.nii.gz'}]\n"
     ]
    }
   ],
   "source": [
    "logdir_path = os.path.normpath(\"./logs/\")\n",
    "\n",
    "#Convert the train and validation images into a list with locations\n",
    "train_dir = \"./Synth3DTrain\"\n",
    "val_dir = \"./Synth3DValTrain\"\n",
    "\n",
    "#train image file\n",
    "timage_filenames = sorted([os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.startswith(\"im\")])\n",
    "tlabel_filenames = sorted([os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.startswith(\"seg\")])\n",
    "\n",
    "#validation image files\n",
    "vimage_filenames = sorted([os.path.join(val_dir, f) for f in os.listdir(val_dir) if f.startswith(\"im\")])\n",
    "vlabel_filenames = sorted([os.path.join(val_dir, f) for f in os.listdir(val_dir) if f.startswith(\"seg\")])\n",
    "\n",
    "# Create a list of dictionaries containing the file paths\n",
    "train_datalist = [{\"image\": img, \"label\": lbl} for img, lbl in zip(vimage_filenames, vlabel_filenames)]\n",
    "validation_datalist = [{\"image\": img, \"label\": lbl} for img, lbl in zip(vimage_filenames, vlabel_filenames)]\n",
    "\n",
    "# Print the datalist to verify\n",
    "print(train_datalist, validation_datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([32, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erattakulangara/.conda/envs/unetSSL/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "# Define Training Transforms\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Spacingd(keys=[\"image\"], pixdim=(2.0, 2.0, 2.0), mode=(\"bilinear\")),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "        SpatialPadd(keys=[\"image\"], spatial_size=(32, 32, 32)),\n",
    "        RandSpatialCropSamplesd(keys=[\"image\"], roi_size=(\n",
    "            32, 32, 32), random_size=False, num_samples=2),\n",
    "        CopyItemsd(keys=[\"image\"], times=2, names=[\n",
    "                   \"gt_image\", \"image_2\"], allow_missing_keys=False),\n",
    "        OneOf(\n",
    "            transforms=[\n",
    "                RandCoarseDropoutd(\n",
    "                    keys=[\"image\"], prob=1.0, holes=6, spatial_size=5, dropout_holes=True, max_spatial_size=32\n",
    "                ),\n",
    "                RandCoarseDropoutd(\n",
    "                    keys=[\"image\"], prob=1.0, holes=6, spatial_size=20, dropout_holes=False, max_spatial_size=64\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        RandCoarseShuffled(keys=[\"image\"], prob=0.8, holes=10, spatial_size=8),\n",
    "        # Please note that that if image, image_2 are called via the same transform call because of the determinism\n",
    "        # they will get augmented the exact same way which is not the required case here, hence two calls are made\n",
    "        OneOf(\n",
    "            transforms=[\n",
    "                RandCoarseDropoutd(\n",
    "                    keys=[\"image_2\"], prob=1.0, holes=6, spatial_size=5, dropout_holes=True, max_spatial_size=32\n",
    "                ),\n",
    "                RandCoarseDropoutd(\n",
    "                    keys=[\"image_2\"], prob=1.0, holes=6, spatial_size=20, dropout_holes=False, max_spatial_size=64\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        RandCoarseShuffled(keys=[\"image_2\"], prob=0.8,\n",
    "                           holes=10, spatial_size=8),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "check_ds = Dataset(data=train_datalist, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "image = check_data[\"image\"][0][0]\n",
    "print(f\"image shape: {image.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Config\n",
    "\n",
    "# Define Network ViT backbone & Loss & Optimizer\n",
    "device = torch.device(\"cpu\")\n",
    "model = ViTAutoEnc(\n",
    "    in_channels=1,\n",
    "    img_size=(32, 32, 32),\n",
    "    patch_size=(16, 16, 16),\n",
    "    proj_type=\"conv\",\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Hyper-paramters for training loop\n",
    "max_epochs = 100\n",
    "val_interval = 2\n",
    "batch_size = 4\n",
    "lr = 1e-4\n",
    "epoch_loss_values = []\n",
    "step_loss_values = []\n",
    "epoch_cl_loss_values = []\n",
    "epoch_recon_loss_values = []\n",
    "val_loss_values = []\n",
    "best_val_loss = 1000.0\n",
    "\n",
    "recon_loss = L1Loss()\n",
    "contrastive_loss = ContrastiveLoss(temperature=0.05)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# Define DataLoader using MONAI, CacheDataset needs to be used\n",
    "train_ds = Dataset(data=train_datalist, transform=train_transforms)\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = Dataset(data=validation_datalist, transform=train_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/100\n",
      "1/2, train_loss: 1.0761, time taken: 4.4858739376068115s\n",
      "2/2, train_loss: 1.0538, time taken: 2.9978647232055664s\n",
      "3/2, train_loss: 0.8224, time taken: 0.7907342910766602s\n",
      "epoch 1 average loss: 0.9841\n",
      "Entering Validation for epoch: 1\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 1 Validation avg loss: 0.2750, time taken: 0.17367196083068848s\n",
      "Saving new model based on validation loss 0.2750\n",
      "----------\n",
      "epoch 2/100\n",
      "1/2, train_loss: 1.0199, time taken: 5.216737270355225s\n",
      "2/2, train_loss: 1.0046, time taken: 0.967797040939331s\n",
      "3/2, train_loss: 0.7872, time taken: 0.8836381435394287s\n",
      "epoch 2 average loss: 0.9372\n",
      "----------\n",
      "epoch 3/100\n",
      "1/2, train_loss: 0.9787, time taken: 5.608540296554565s\n",
      "2/2, train_loss: 0.9652, time taken: 1.2107508182525635s\n",
      "3/2, train_loss: 0.7570, time taken: 0.9905765056610107s\n",
      "epoch 3 average loss: 0.9003\n",
      "Entering Validation for epoch: 3\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 3 Validation avg loss: 0.2540, time taken: 0.10064172744750977s\n",
      "Saving new model based on validation loss 0.2540\n",
      "----------\n",
      "epoch 4/100\n",
      "1/2, train_loss: 0.9418, time taken: 4.902584552764893s\n",
      "2/2, train_loss: 0.9313, time taken: 1.0018062591552734s\n",
      "3/2, train_loss: 0.7318, time taken: 0.6923434734344482s\n",
      "epoch 4 average loss: 0.8683\n",
      "----------\n",
      "epoch 5/100\n",
      "1/2, train_loss: 0.9110, time taken: 5.17902398109436s\n",
      "2/2, train_loss: 0.9012, time taken: 1.173865795135498s\n",
      "3/2, train_loss: 0.7080, time taken: 0.7349693775177002s\n",
      "epoch 5 average loss: 0.8401\n",
      "Entering Validation for epoch: 5\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 5 Validation avg loss: 0.2378, time taken: 0.10646414756774902s\n",
      "Saving new model based on validation loss 0.2378\n",
      "----------\n",
      "epoch 6/100\n",
      "1/2, train_loss: 0.8817, time taken: 4.9815757274627686s\n",
      "2/2, train_loss: 0.8725, time taken: 0.8038012981414795s\n",
      "3/2, train_loss: 0.6861, time taken: 0.77821946144104s\n",
      "epoch 6 average loss: 0.8134\n",
      "----------\n",
      "epoch 7/100\n",
      "1/2, train_loss: 0.8544, time taken: 5.21606183052063s\n",
      "2/2, train_loss: 0.8461, time taken: 1.0737025737762451s\n",
      "3/2, train_loss: 0.6658, time taken: 0.7903778553009033s\n",
      "epoch 7 average loss: 0.7888\n",
      "Entering Validation for epoch: 7\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 7 Validation avg loss: 0.2239, time taken: 0.12459301948547363s\n",
      "Saving new model based on validation loss 0.2239\n",
      "----------\n",
      "epoch 8/100\n",
      "1/2, train_loss: 0.8300, time taken: 5.5014636516571045s\n",
      "2/2, train_loss: 0.8222, time taken: 1.079026222229004s\n",
      "3/2, train_loss: 0.6483, time taken: 0.7108700275421143s\n",
      "epoch 8 average loss: 0.7668\n",
      "----------\n",
      "epoch 9/100\n",
      "1/2, train_loss: 0.8091, time taken: 5.163847923278809s\n",
      "2/2, train_loss: 0.8012, time taken: 1.275984287261963s\n",
      "3/2, train_loss: 0.6314, time taken: 0.7209892272949219s\n",
      "epoch 9 average loss: 0.7472\n",
      "Entering Validation for epoch: 9\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 9 Validation avg loss: 0.2125, time taken: 0.11802172660827637s\n",
      "Saving new model based on validation loss 0.2125\n",
      "----------\n",
      "epoch 10/100\n",
      "1/2, train_loss: 0.7878, time taken: 5.576168775558472s\n",
      "2/2, train_loss: 0.7807, time taken: 1.0973081588745117s\n",
      "3/2, train_loss: 0.6155, time taken: 0.8059935569763184s\n",
      "epoch 10 average loss: 0.7280\n",
      "----------\n",
      "epoch 11/100\n",
      "1/2, train_loss: 0.7683, time taken: 5.452242612838745s\n",
      "2/2, train_loss: 0.7613, time taken: 1.5097074508666992s\n",
      "3/2, train_loss: 0.5994, time taken: 1.3783366680145264s\n",
      "epoch 11 average loss: 0.7097\n",
      "Entering Validation for epoch: 11\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 11 Validation avg loss: 0.2019, time taken: 0.10994505882263184s\n",
      "Saving new model based on validation loss 0.2019\n",
      "----------\n",
      "epoch 12/100\n",
      "1/2, train_loss: 0.7488, time taken: 5.820004940032959s\n",
      "2/2, train_loss: 0.7426, time taken: 0.8470332622528076s\n",
      "3/2, train_loss: 0.5847, time taken: 0.7048935890197754s\n",
      "epoch 12 average loss: 0.6920\n",
      "----------\n",
      "epoch 13/100\n",
      "1/2, train_loss: 0.7307, time taken: 5.516984224319458s\n",
      "2/2, train_loss: 0.7242, time taken: 0.89996337890625s\n",
      "3/2, train_loss: 0.5711, time taken: 0.7825636863708496s\n",
      "epoch 13 average loss: 0.6753\n",
      "Entering Validation for epoch: 13\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 13 Validation avg loss: 0.1923, time taken: 0.18480777740478516s\n",
      "Saving new model based on validation loss 0.1923\n",
      "----------\n",
      "epoch 14/100\n",
      "1/2, train_loss: 0.7129, time taken: 5.380509853363037s\n",
      "2/2, train_loss: 0.7074, time taken: 0.8792731761932373s\n",
      "3/2, train_loss: 0.5573, time taken: 0.8135197162628174s\n",
      "epoch 14 average loss: 0.6592\n",
      "----------\n",
      "epoch 15/100\n",
      "1/2, train_loss: 0.6960, time taken: 5.057124137878418s\n",
      "2/2, train_loss: 0.6910, time taken: 1.4714295864105225s\n",
      "3/2, train_loss: 0.5447, time taken: 0.7294750213623047s\n",
      "epoch 15 average loss: 0.6439\n",
      "Entering Validation for epoch: 15\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 15 Validation avg loss: 0.1835, time taken: 0.13219237327575684s\n",
      "Saving new model based on validation loss 0.1835\n",
      "----------\n",
      "epoch 16/100\n",
      "1/2, train_loss: 0.6808, time taken: 5.19376277923584s\n",
      "2/2, train_loss: 0.6751, time taken: 1.6950581073760986s\n",
      "3/2, train_loss: 0.5321, time taken: 0.7873489856719971s\n",
      "epoch 16 average loss: 0.6293\n",
      "----------\n",
      "epoch 17/100\n",
      "1/2, train_loss: 0.6655, time taken: 5.197494745254517s\n",
      "2/2, train_loss: 0.6607, time taken: 0.992835521697998s\n",
      "3/2, train_loss: 0.5211, time taken: 0.8040280342102051s\n",
      "epoch 17 average loss: 0.6158\n",
      "Entering Validation for epoch: 17\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 17 Validation avg loss: 0.1756, time taken: 0.1686091423034668s\n",
      "Saving new model based on validation loss 0.1756\n",
      "----------\n",
      "epoch 18/100\n",
      "1/2, train_loss: 0.6513, time taken: 4.980530261993408s\n",
      "2/2, train_loss: 0.6465, time taken: 1.0066838264465332s\n",
      "3/2, train_loss: 0.5099, time taken: 0.7886676788330078s\n",
      "epoch 18 average loss: 0.6026\n",
      "----------\n",
      "epoch 19/100\n",
      "1/2, train_loss: 0.6374, time taken: 5.174107313156128s\n",
      "2/2, train_loss: 0.6326, time taken: 1.0884146690368652s\n",
      "3/2, train_loss: 0.4987, time taken: 0.7944869995117188s\n",
      "epoch 19 average loss: 0.5896\n",
      "Entering Validation for epoch: 19\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 19 Validation avg loss: 0.1681, time taken: 0.18236279487609863s\n",
      "Saving new model based on validation loss 0.1681\n",
      "----------\n",
      "epoch 20/100\n",
      "1/2, train_loss: 0.6233, time taken: 5.932753324508667s\n",
      "2/2, train_loss: 0.6191, time taken: 0.9006145000457764s\n",
      "3/2, train_loss: 0.4877, time taken: 2.0030152797698975s\n",
      "epoch 20 average loss: 0.5767\n",
      "----------\n",
      "epoch 21/100\n",
      "1/2, train_loss: 0.6095, time taken: 5.06640625s\n",
      "2/2, train_loss: 0.6057, time taken: 1.0121691226959229s\n",
      "3/2, train_loss: 0.4786, time taken: 0.8817541599273682s\n",
      "epoch 21 average loss: 0.5646\n",
      "Entering Validation for epoch: 21\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 21 Validation avg loss: 0.1612, time taken: 0.1830885410308838s\n",
      "Saving new model based on validation loss 0.1612\n",
      "----------\n",
      "epoch 22/100\n",
      "1/2, train_loss: 0.5977, time taken: 5.106112480163574s\n",
      "2/2, train_loss: 0.5931, time taken: 0.9484937191009521s\n",
      "3/2, train_loss: 0.4683, time taken: 0.7226028442382812s\n",
      "epoch 22 average loss: 0.5531\n",
      "----------\n",
      "epoch 23/100\n",
      "1/2, train_loss: 0.5849, time taken: 5.739044904708862s\n",
      "2/2, train_loss: 0.5812, time taken: 0.876812219619751s\n",
      "3/2, train_loss: 0.4584, time taken: 0.7709782123565674s\n",
      "epoch 23 average loss: 0.5415\n",
      "Entering Validation for epoch: 23\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 23 Validation avg loss: 0.1544, time taken: 0.13174724578857422s\n",
      "Saving new model based on validation loss 0.1544\n",
      "----------\n",
      "epoch 24/100\n",
      "1/2, train_loss: 0.5726, time taken: 5.249611854553223s\n",
      "2/2, train_loss: 0.5685, time taken: 0.7758800983428955s\n",
      "3/2, train_loss: 0.4482, time taken: 0.7135946750640869s\n",
      "epoch 24 average loss: 0.5298\n",
      "----------\n",
      "epoch 25/100\n",
      "1/2, train_loss: 0.5601, time taken: 5.08101487159729s\n",
      "2/2, train_loss: 0.5558, time taken: 1.2081019878387451s\n",
      "3/2, train_loss: 0.4380, time taken: 0.7732629776000977s\n",
      "epoch 25 average loss: 0.5179\n",
      "Entering Validation for epoch: 25\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 25 Validation avg loss: 0.1476, time taken: 0.13085532188415527s\n",
      "Saving new model based on validation loss 0.1476\n",
      "----------\n",
      "epoch 26/100\n",
      "1/2, train_loss: 0.5473, time taken: 5.623838186264038s\n",
      "2/2, train_loss: 0.5429, time taken: 1.5750837326049805s\n",
      "3/2, train_loss: 0.4281, time taken: 0.8254358768463135s\n",
      "epoch 26 average loss: 0.5061\n",
      "----------\n",
      "epoch 27/100\n",
      "1/2, train_loss: 0.5344, time taken: 4.972937345504761s\n",
      "2/2, train_loss: 0.5308, time taken: 1.0137662887573242s\n",
      "3/2, train_loss: 0.4179, time taken: 0.779679536819458s\n",
      "epoch 27 average loss: 0.4944\n",
      "Entering Validation for epoch: 27\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 27 Validation avg loss: 0.1407, time taken: 0.26454925537109375s\n",
      "Saving new model based on validation loss 0.1407\n",
      "----------\n",
      "epoch 28/100\n",
      "1/2, train_loss: 0.5217, time taken: 5.337780237197876s\n",
      "2/2, train_loss: 0.5184, time taken: 0.8038074970245361s\n",
      "3/2, train_loss: 0.4081, time taken: 0.7837717533111572s\n",
      "epoch 28 average loss: 0.4827\n",
      "----------\n",
      "epoch 29/100\n",
      "1/2, train_loss: 0.5099, time taken: 5.533888339996338s\n",
      "2/2, train_loss: 0.5061, time taken: 1.0771899223327637s\n",
      "3/2, train_loss: 0.3989, time taken: 0.8017845153808594s\n",
      "epoch 29 average loss: 0.4716\n",
      "Entering Validation for epoch: 29\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 29 Validation avg loss: 0.1342, time taken: 0.18508577346801758s\n",
      "Saving new model based on validation loss 0.1342\n",
      "----------\n",
      "epoch 30/100\n",
      "1/2, train_loss: 0.4977, time taken: 5.32717490196228s\n",
      "2/2, train_loss: 0.4933, time taken: 1.0940022468566895s\n",
      "3/2, train_loss: 0.3886, time taken: 0.8229866027832031s\n",
      "epoch 30 average loss: 0.4598\n",
      "----------\n",
      "epoch 31/100\n",
      "1/2, train_loss: 0.4851, time taken: 5.489414930343628s\n",
      "2/2, train_loss: 0.4807, time taken: 0.9008572101593018s\n",
      "3/2, train_loss: 0.3782, time taken: 0.7835490703582764s\n",
      "epoch 31 average loss: 0.4480\n",
      "Entering Validation for epoch: 31\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 31 Validation avg loss: 0.1272, time taken: 0.1985795497894287s\n",
      "Saving new model based on validation loss 0.1272\n",
      "----------\n",
      "epoch 32/100\n",
      "1/2, train_loss: 0.4715, time taken: 5.796572685241699s\n",
      "2/2, train_loss: 0.4674, time taken: 1.1723148822784424s\n",
      "3/2, train_loss: 0.3673, time taken: 0.8103008270263672s\n",
      "epoch 32 average loss: 0.4354\n",
      "----------\n",
      "epoch 33/100\n",
      "1/2, train_loss: 0.4582, time taken: 5.322524547576904s\n",
      "2/2, train_loss: 0.4532, time taken: 0.8931779861450195s\n",
      "3/2, train_loss: 0.3566, time taken: 1.1634528636932373s\n",
      "epoch 33 average loss: 0.4226\n",
      "Entering Validation for epoch: 33\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 33 Validation avg loss: 0.1198, time taken: 0.18085312843322754s\n",
      "Saving new model based on validation loss 0.1198\n",
      "----------\n",
      "epoch 34/100\n",
      "1/2, train_loss: 0.4444, time taken: 6.32276725769043s\n",
      "2/2, train_loss: 0.4393, time taken: 0.9802324771881104s\n",
      "3/2, train_loss: 0.3453, time taken: 0.9843025207519531s\n",
      "epoch 34 average loss: 0.4097\n",
      "----------\n",
      "epoch 35/100\n",
      "1/2, train_loss: 0.4309, time taken: 4.962406158447266s\n",
      "2/2, train_loss: 0.4263, time taken: 1.083540916442871s\n",
      "3/2, train_loss: 0.3352, time taken: 0.7481675148010254s\n",
      "epoch 35 average loss: 0.3974\n",
      "Entering Validation for epoch: 35\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 35 Validation avg loss: 0.1127, time taken: 0.18424725532531738s\n",
      "Saving new model based on validation loss 0.1127\n",
      "----------\n",
      "epoch 36/100\n",
      "1/2, train_loss: 0.4181, time taken: 5.808543682098389s\n",
      "2/2, train_loss: 0.4134, time taken: 1.065093755722046s\n",
      "3/2, train_loss: 0.3248, time taken: 0.8254232406616211s\n",
      "epoch 36 average loss: 0.3854\n",
      "----------\n",
      "epoch 37/100\n",
      "1/2, train_loss: 0.4049, time taken: 5.306564807891846s\n",
      "2/2, train_loss: 0.4003, time taken: 0.9804847240447998s\n",
      "3/2, train_loss: 0.3151, time taken: 0.801722526550293s\n",
      "epoch 37 average loss: 0.3735\n",
      "Entering Validation for epoch: 37\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 37 Validation avg loss: 0.1058, time taken: 0.18872737884521484s\n",
      "Saving new model based on validation loss 0.1058\n",
      "----------\n",
      "epoch 38/100\n",
      "1/2, train_loss: 0.3924, time taken: 5.5166566371917725s\n",
      "2/2, train_loss: 0.3878, time taken: 1.4738914966583252s\n",
      "3/2, train_loss: 0.3052, time taken: 0.9937875270843506s\n",
      "epoch 38 average loss: 0.3618\n",
      "----------\n",
      "epoch 39/100\n",
      "1/2, train_loss: 0.3797, time taken: 5.516980886459351s\n",
      "2/2, train_loss: 0.3755, time taken: 1.1902046203613281s\n",
      "3/2, train_loss: 0.2946, time taken: 1.6059818267822266s\n",
      "epoch 39 average loss: 0.3499\n",
      "Entering Validation for epoch: 39\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 39 Validation avg loss: 0.0989, time taken: 0.18277835845947266s\n",
      "Saving new model based on validation loss 0.0989\n",
      "----------\n",
      "epoch 40/100\n",
      "1/2, train_loss: 0.3670, time taken: 5.214473724365234s\n",
      "2/2, train_loss: 0.3621, time taken: 2.364046573638916s\n",
      "3/2, train_loss: 0.2844, time taken: 0.8180081844329834s\n",
      "epoch 40 average loss: 0.3378\n",
      "----------\n",
      "epoch 41/100\n",
      "1/2, train_loss: 0.3541, time taken: 5.575613737106323s\n",
      "2/2, train_loss: 0.3503, time taken: 2.686830997467041s\n",
      "3/2, train_loss: 0.2751, time taken: 0.7985053062438965s\n",
      "epoch 41 average loss: 0.3265\n",
      "Entering Validation for epoch: 41\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 41 Validation avg loss: 0.0924, time taken: 0.19088172912597656s\n",
      "Saving new model based on validation loss 0.0924\n",
      "----------\n",
      "epoch 42/100\n",
      "1/2, train_loss: 0.3424, time taken: 5.176784992218018s\n",
      "2/2, train_loss: 0.3388, time taken: 2.721245050430298s\n",
      "3/2, train_loss: 0.2657, time taken: 0.795236349105835s\n",
      "epoch 42 average loss: 0.3156\n",
      "----------\n",
      "epoch 43/100\n",
      "1/2, train_loss: 0.3305, time taken: 5.704560995101929s\n",
      "2/2, train_loss: 0.3262, time taken: 1.2643754482269287s\n",
      "3/2, train_loss: 0.2555, time taken: 0.9072751998901367s\n",
      "epoch 43 average loss: 0.3041\n",
      "Entering Validation for epoch: 43\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 43 Validation avg loss: 0.0856, time taken: 0.20197439193725586s\n",
      "Saving new model based on validation loss 0.0856\n",
      "----------\n",
      "epoch 44/100\n",
      "1/2, train_loss: 0.3176, time taken: 5.492749214172363s\n",
      "2/2, train_loss: 0.3134, time taken: 0.8749938011169434s\n",
      "3/2, train_loss: 0.2456, time taken: 0.7878808975219727s\n",
      "epoch 44 average loss: 0.2922\n",
      "----------\n",
      "epoch 45/100\n",
      "1/2, train_loss: 0.3055, time taken: 5.583327531814575s\n",
      "2/2, train_loss: 0.3011, time taken: 1.1211810111999512s\n",
      "3/2, train_loss: 0.2361, time taken: 0.9644722938537598s\n",
      "epoch 45 average loss: 0.2809\n",
      "Entering Validation for epoch: 45\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 45 Validation avg loss: 0.0792, time taken: 0.18602371215820312s\n",
      "Saving new model based on validation loss 0.0792\n",
      "----------\n",
      "epoch 46/100\n",
      "1/2, train_loss: 0.2936, time taken: 5.30126953125s\n",
      "2/2, train_loss: 0.2901, time taken: 0.878474235534668s\n",
      "3/2, train_loss: 0.2272, time taken: 0.8292708396911621s\n",
      "epoch 46 average loss: 0.2703\n",
      "----------\n",
      "epoch 47/100\n",
      "1/2, train_loss: 0.2828, time taken: 5.464641094207764s\n",
      "2/2, train_loss: 0.2787, time taken: 1.061004877090454s\n",
      "3/2, train_loss: 0.2184, time taken: 1.6354877948760986s\n",
      "epoch 47 average loss: 0.2600\n",
      "Entering Validation for epoch: 47\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 47 Validation avg loss: 0.0732, time taken: 0.17550134658813477s\n",
      "Saving new model based on validation loss 0.0732\n",
      "----------\n",
      "epoch 48/100\n",
      "1/2, train_loss: 0.2712, time taken: 5.152700901031494s\n",
      "2/2, train_loss: 0.2677, time taken: 2.4968063831329346s\n",
      "3/2, train_loss: 0.2093, time taken: 0.7899012565612793s\n",
      "epoch 48 average loss: 0.2494\n",
      "----------\n",
      "epoch 49/100\n",
      "1/2, train_loss: 0.2597, time taken: 5.715606927871704s\n",
      "2/2, train_loss: 0.2560, time taken: 0.993988037109375s\n",
      "3/2, train_loss: 0.2004, time taken: 0.7892451286315918s\n",
      "epoch 49 average loss: 0.2387\n",
      "Entering Validation for epoch: 49\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 49 Validation avg loss: 0.0672, time taken: 0.20022153854370117s\n",
      "Saving new model based on validation loss 0.0672\n",
      "----------\n",
      "epoch 50/100\n",
      "1/2, train_loss: 0.2493, time taken: 5.5048487186431885s\n",
      "2/2, train_loss: 0.2461, time taken: 0.8930096626281738s\n",
      "3/2, train_loss: 0.1927, time taken: 0.8761386871337891s\n",
      "epoch 50 average loss: 0.2294\n",
      "----------\n",
      "epoch 51/100\n",
      "1/2, train_loss: 0.2397, time taken: 5.242205381393433s\n",
      "2/2, train_loss: 0.2368, time taken: 1.1073386669158936s\n",
      "3/2, train_loss: 0.1856, time taken: 1.6014127731323242s\n",
      "epoch 51 average loss: 0.2207\n",
      "Entering Validation for epoch: 51\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 51 Validation avg loss: 0.0622, time taken: 0.27602100372314453s\n",
      "Saving new model based on validation loss 0.0622\n",
      "----------\n",
      "epoch 52/100\n",
      "1/2, train_loss: 0.2308, time taken: 5.678560018539429s\n",
      "2/2, train_loss: 0.2285, time taken: 0.8700995445251465s\n",
      "3/2, train_loss: 0.1794, time taken: 0.7974052429199219s\n",
      "epoch 52 average loss: 0.2129\n",
      "----------\n",
      "epoch 53/100\n",
      "1/2, train_loss: 0.2234, time taken: 5.665404319763184s\n",
      "2/2, train_loss: 0.2218, time taken: 1.0217933654785156s\n",
      "3/2, train_loss: 0.1743, time taken: 0.7789092063903809s\n",
      "epoch 53 average loss: 0.2065\n",
      "Entering Validation for epoch: 53\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 53 Validation avg loss: 0.0586, time taken: 0.26795411109924316s\n",
      "Saving new model based on validation loss 0.0586\n",
      "----------\n",
      "epoch 54/100\n",
      "1/2, train_loss: 0.2172, time taken: 5.318022012710571s\n",
      "2/2, train_loss: 0.2152, time taken: 1.1514582633972168s\n",
      "3/2, train_loss: 0.1684, time taken: 1.940490961074829s\n",
      "epoch 54 average loss: 0.2003\n",
      "----------\n",
      "epoch 55/100\n",
      "1/2, train_loss: 0.2100, time taken: 5.240523099899292s\n",
      "2/2, train_loss: 0.2074, time taken: 1.2804286479949951s\n",
      "3/2, train_loss: 0.1627, time taken: 1.5834119319915771s\n",
      "epoch 55 average loss: 0.1934\n",
      "Entering Validation for epoch: 55\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 55 Validation avg loss: 0.0546, time taken: 0.18529343605041504s\n",
      "Saving new model based on validation loss 0.0546\n",
      "----------\n",
      "epoch 56/100\n",
      "1/2, train_loss: 0.2026, time taken: 5.0621936321258545s\n",
      "2/2, train_loss: 0.1998, time taken: 0.9972329139709473s\n",
      "3/2, train_loss: 0.1571, time taken: 2.3137741088867188s\n",
      "epoch 56 average loss: 0.1865\n",
      "----------\n",
      "epoch 57/100\n",
      "1/2, train_loss: 0.1949, time taken: 5.208166837692261s\n",
      "2/2, train_loss: 0.1927, time taken: 1.5073671340942383s\n",
      "3/2, train_loss: 0.1510, time taken: 0.8918945789337158s\n",
      "epoch 57 average loss: 0.1796\n",
      "Entering Validation for epoch: 57\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 57 Validation avg loss: 0.0506, time taken: 0.19192981719970703s\n",
      "Saving new model based on validation loss 0.0506\n",
      "----------\n",
      "epoch 58/100\n",
      "1/2, train_loss: 0.1875, time taken: 5.66865611076355s\n",
      "2/2, train_loss: 0.1863, time taken: 2.373213768005371s\n",
      "3/2, train_loss: 0.1459, time taken: 0.8241589069366455s\n",
      "epoch 58 average loss: 0.1732\n",
      "----------\n",
      "epoch 59/100\n",
      "1/2, train_loss: 0.1813, time taken: 4.969373464584351s\n",
      "2/2, train_loss: 0.1798, time taken: 1.0064280033111572s\n",
      "3/2, train_loss: 0.1409, time taken: 0.8793802261352539s\n",
      "epoch 59 average loss: 0.1673\n",
      "Entering Validation for epoch: 59\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 59 Validation avg loss: 0.0474, time taken: 0.20399260520935059s\n",
      "Saving new model based on validation loss 0.0474\n",
      "----------\n",
      "epoch 60/100\n",
      "1/2, train_loss: 0.1759, time taken: 5.971450090408325s\n",
      "2/2, train_loss: 0.1739, time taken: 1.0942625999450684s\n",
      "3/2, train_loss: 0.1363, time taken: 0.8825435638427734s\n",
      "epoch 60 average loss: 0.1620\n",
      "----------\n",
      "epoch 61/100\n",
      "1/2, train_loss: 0.1704, time taken: 5.51707911491394s\n",
      "2/2, train_loss: 0.1684, time taken: 0.989166259765625s\n",
      "3/2, train_loss: 0.1316, time taken: 0.777195930480957s\n",
      "epoch 61 average loss: 0.1568\n",
      "Entering Validation for epoch: 61\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 61 Validation avg loss: 0.0445, time taken: 0.2870054244995117s\n",
      "Saving new model based on validation loss 0.0445\n",
      "----------\n",
      "epoch 62/100\n",
      "1/2, train_loss: 0.1651, time taken: 5.506377935409546s\n",
      "2/2, train_loss: 0.1626, time taken: 0.8833792209625244s\n",
      "3/2, train_loss: 0.1274, time taken: 0.7824034690856934s\n",
      "epoch 62 average loss: 0.1517\n",
      "----------\n",
      "epoch 63/100\n",
      "1/2, train_loss: 0.1592, time taken: 6.041024923324585s\n",
      "2/2, train_loss: 0.1573, time taken: 1.1063232421875s\n",
      "3/2, train_loss: 0.1229, time taken: 0.8807330131530762s\n",
      "epoch 63 average loss: 0.1465\n",
      "Entering Validation for epoch: 63\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 63 Validation avg loss: 0.0414, time taken: 0.17485785484313965s\n",
      "Saving new model based on validation loss 0.0414\n",
      "----------\n",
      "epoch 64/100\n",
      "1/2, train_loss: 0.1536, time taken: 5.915009260177612s\n",
      "2/2, train_loss: 0.1516, time taken: 1.2747113704681396s\n",
      "3/2, train_loss: 0.1190, time taken: 0.8774008750915527s\n",
      "epoch 64 average loss: 0.1414\n",
      "----------\n",
      "epoch 65/100\n",
      "1/2, train_loss: 0.1480, time taken: 5.39480996131897s\n",
      "2/2, train_loss: 0.1467, time taken: 0.953704833984375s\n",
      "3/2, train_loss: 0.1147, time taken: 0.7295451164245605s\n",
      "epoch 65 average loss: 0.1365\n",
      "Entering Validation for epoch: 65\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 65 Validation avg loss: 0.0385, time taken: 0.250093936920166s\n",
      "Saving new model based on validation loss 0.0385\n",
      "----------\n",
      "epoch 66/100\n",
      "1/2, train_loss: 0.1427, time taken: 5.0571372509002686s\n",
      "2/2, train_loss: 0.1420, time taken: 0.9018125534057617s\n",
      "3/2, train_loss: 0.1104, time taken: 0.8855187892913818s\n",
      "epoch 66 average loss: 0.1317\n",
      "----------\n",
      "epoch 67/100\n",
      "1/2, train_loss: 0.1379, time taken: 5.620375633239746s\n",
      "2/2, train_loss: 0.1352, time taken: 0.9182620048522949s\n",
      "3/2, train_loss: 0.1059, time taken: 0.8708627223968506s\n",
      "epoch 67 average loss: 0.1263\n",
      "Entering Validation for epoch: 67\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 67 Validation avg loss: 0.0356, time taken: 0.2138521671295166s\n",
      "Saving new model based on validation loss 0.0356\n",
      "----------\n",
      "epoch 68/100\n",
      "1/2, train_loss: 0.1321, time taken: 6.087859153747559s\n",
      "2/2, train_loss: 0.1292, time taken: 0.8867008686065674s\n",
      "3/2, train_loss: 0.1011, time taken: 0.8754324913024902s\n",
      "epoch 68 average loss: 0.1208\n",
      "----------\n",
      "epoch 69/100\n",
      "1/2, train_loss: 0.1259, time taken: 4.897334575653076s\n",
      "2/2, train_loss: 0.1240, time taken: 1.0935847759246826s\n",
      "3/2, train_loss: 0.0966, time taken: 0.7873580455780029s\n",
      "epoch 69 average loss: 0.1155\n",
      "Entering Validation for epoch: 69\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 69 Validation avg loss: 0.0325, time taken: 0.24789810180664062s\n",
      "Saving new model based on validation loss 0.0325\n",
      "----------\n",
      "epoch 70/100\n",
      "1/2, train_loss: 0.1202, time taken: 5.927345037460327s\n",
      "2/2, train_loss: 0.1195, time taken: 1.0413827896118164s\n",
      "3/2, train_loss: 0.0927, time taken: 2.137586832046509s\n",
      "epoch 70 average loss: 0.1108\n",
      "----------\n",
      "epoch 71/100\n",
      "1/2, train_loss: 0.1162, time taken: 6.119585275650024s\n",
      "2/2, train_loss: 0.1147, time taken: 1.084543228149414s\n",
      "3/2, train_loss: 0.0892, time taken: 0.814976692199707s\n",
      "epoch 71 average loss: 0.1067\n",
      "Entering Validation for epoch: 71\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 71 Validation avg loss: 0.0301, time taken: 0.1864337921142578s\n",
      "Saving new model based on validation loss 0.0301\n",
      "----------\n",
      "epoch 72/100\n",
      "1/2, train_loss: 0.1117, time taken: 5.4098100662231445s\n",
      "2/2, train_loss: 0.1099, time taken: 0.8695495128631592s\n",
      "3/2, train_loss: 0.0852, time taken: 0.7865405082702637s\n",
      "epoch 72 average loss: 0.1023\n",
      "----------\n",
      "epoch 73/100\n",
      "1/2, train_loss: 0.1066, time taken: 5.846715927124023s\n",
      "2/2, train_loss: 0.1047, time taken: 1.0232112407684326s\n",
      "3/2, train_loss: 0.0813, time taken: 1.4599156379699707s\n",
      "epoch 73 average loss: 0.0975\n",
      "Entering Validation for epoch: 73\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 73 Validation avg loss: 0.0273, time taken: 0.19936823844909668s\n",
      "Saving new model based on validation loss 0.0273\n",
      "----------\n",
      "epoch 74/100\n",
      "1/2, train_loss: 0.1010, time taken: 5.03725266456604s\n",
      "2/2, train_loss: 0.0992, time taken: 0.9850072860717773s\n",
      "3/2, train_loss: 0.0771, time taken: 0.7083251476287842s\n",
      "epoch 74 average loss: 0.0925\n",
      "----------\n",
      "epoch 75/100\n",
      "1/2, train_loss: 0.0962, time taken: 5.455299615859985s\n",
      "2/2, train_loss: 0.0949, time taken: 1.204791784286499s\n",
      "3/2, train_loss: 0.0733, time taken: 0.8098969459533691s\n",
      "epoch 75 average loss: 0.0882\n",
      "Entering Validation for epoch: 75\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 75 Validation avg loss: 0.0247, time taken: 0.204728364944458s\n",
      "Saving new model based on validation loss 0.0247\n",
      "----------\n",
      "epoch 76/100\n",
      "1/2, train_loss: 0.0915, time taken: 5.383699178695679s\n",
      "2/2, train_loss: 0.0905, time taken: 1.808438777923584s\n",
      "3/2, train_loss: 0.0702, time taken: 0.8717963695526123s\n",
      "epoch 76 average loss: 0.0841\n",
      "----------\n",
      "epoch 77/100\n",
      "1/2, train_loss: 0.0873, time taken: 5.193635702133179s\n",
      "2/2, train_loss: 0.0867, time taken: 1.2030935287475586s\n",
      "3/2, train_loss: 0.0659, time taken: 0.8859763145446777s\n",
      "epoch 77 average loss: 0.0800\n",
      "Entering Validation for epoch: 77\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 77 Validation avg loss: 0.0225, time taken: 0.25094079971313477s\n",
      "Saving new model based on validation loss 0.0225\n",
      "----------\n",
      "epoch 78/100\n",
      "1/2, train_loss: 0.0833, time taken: 5.208807468414307s\n",
      "2/2, train_loss: 0.0813, time taken: 0.9020280838012695s\n",
      "3/2, train_loss: 0.0627, time taken: 0.7052948474884033s\n",
      "epoch 78 average loss: 0.0758\n",
      "----------\n",
      "epoch 79/100\n",
      "1/2, train_loss: 0.0779, time taken: 5.411019563674927s\n",
      "2/2, train_loss: 0.0764, time taken: 1.18312668800354s\n",
      "3/2, train_loss: 0.0589, time taken: 1.1104092597961426s\n",
      "epoch 79 average loss: 0.0711\n",
      "Entering Validation for epoch: 79\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 79 Validation avg loss: 0.0197, time taken: 0.19763588905334473s\n",
      "Saving new model based on validation loss 0.0197\n",
      "----------\n",
      "epoch 80/100\n",
      "1/2, train_loss: 0.0732, time taken: 5.283987998962402s\n",
      "2/2, train_loss: 0.0724, time taken: 0.9937162399291992s\n",
      "3/2, train_loss: 0.0552, time taken: 0.7865891456604004s\n",
      "epoch 80 average loss: 0.0669\n",
      "----------\n",
      "epoch 81/100\n",
      "1/2, train_loss: 0.0696, time taken: 5.5574798583984375s\n",
      "2/2, train_loss: 0.0687, time taken: 1.0430402755737305s\n",
      "3/2, train_loss: 0.0535, time taken: 0.7717525959014893s\n",
      "epoch 81 average loss: 0.0639\n",
      "Entering Validation for epoch: 81\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 81 Validation avg loss: 0.0180, time taken: 0.24205994606018066s\n",
      "Saving new model based on validation loss 0.0180\n",
      "----------\n",
      "epoch 82/100\n",
      "1/2, train_loss: 0.0668, time taken: 5.423092603683472s\n",
      "2/2, train_loss: 0.0669, time taken: 1.1138546466827393s\n",
      "3/2, train_loss: 0.0514, time taken: 0.7967939376831055s\n",
      "epoch 82 average loss: 0.0617\n",
      "----------\n",
      "epoch 83/100\n",
      "1/2, train_loss: 0.0643, time taken: 5.791393518447876s\n",
      "2/2, train_loss: 0.0632, time taken: 1.3717458248138428s\n",
      "3/2, train_loss: 0.0487, time taken: 0.7364106178283691s\n",
      "epoch 83 average loss: 0.0587\n",
      "Entering Validation for epoch: 83\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 83 Validation avg loss: 0.0164, time taken: 0.26648378372192383s\n",
      "Saving new model based on validation loss 0.0164\n",
      "----------\n",
      "epoch 84/100\n",
      "1/2, train_loss: 0.0609, time taken: 5.342621803283691s\n",
      "2/2, train_loss: 0.0600, time taken: 0.8867037296295166s\n",
      "3/2, train_loss: 0.0463, time taken: 1.0693893432617188s\n",
      "epoch 84 average loss: 0.0557\n",
      "----------\n",
      "epoch 85/100\n",
      "1/2, train_loss: 0.0582, time taken: 5.255448341369629s\n",
      "2/2, train_loss: 0.0575, time taken: 1.079547643661499s\n",
      "3/2, train_loss: 0.0436, time taken: 1.8241724967956543s\n",
      "epoch 85 average loss: 0.0531\n",
      "Entering Validation for epoch: 85\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 85 Validation avg loss: 0.0151, time taken: 0.2039787769317627s\n",
      "Saving new model based on validation loss 0.0151\n",
      "----------\n",
      "epoch 86/100\n",
      "1/2, train_loss: 0.0559, time taken: 5.39997124671936s\n",
      "2/2, train_loss: 0.0538, time taken: 1.3728878498077393s\n",
      "3/2, train_loss: 0.0421, time taken: 0.7262105941772461s\n",
      "epoch 86 average loss: 0.0506\n",
      "----------\n",
      "epoch 87/100\n",
      "1/2, train_loss: 0.0519, time taken: 5.324265718460083s\n",
      "2/2, train_loss: 0.0515, time taken: 0.8851113319396973s\n",
      "3/2, train_loss: 0.0401, time taken: 0.7884745597839355s\n",
      "epoch 87 average loss: 0.0478\n",
      "Entering Validation for epoch: 87\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 87 Validation avg loss: 0.0134, time taken: 0.19259881973266602s\n",
      "Saving new model based on validation loss 0.0134\n",
      "----------\n",
      "epoch 88/100\n",
      "1/2, train_loss: 0.0495, time taken: 6.3056464195251465s\n",
      "2/2, train_loss: 0.0490, time taken: 1.006147861480713s\n",
      "3/2, train_loss: 0.0379, time taken: 0.8943614959716797s\n",
      "epoch 88 average loss: 0.0455\n",
      "----------\n",
      "epoch 89/100\n",
      "1/2, train_loss: 0.0473, time taken: 5.517791986465454s\n",
      "2/2, train_loss: 0.0464, time taken: 2.771566390991211s\n",
      "3/2, train_loss: 0.0350, time taken: 0.805272102355957s\n",
      "epoch 89 average loss: 0.0429\n",
      "Entering Validation for epoch: 89\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 89 Validation avg loss: 0.0120, time taken: 0.269059419631958s\n",
      "Saving new model based on validation loss 0.0120\n",
      "----------\n",
      "epoch 90/100\n",
      "1/2, train_loss: 0.0444, time taken: 5.6226441860198975s\n",
      "2/2, train_loss: 0.0432, time taken: 2.1652963161468506s\n",
      "3/2, train_loss: 0.0331, time taken: 0.9040098190307617s\n",
      "epoch 90 average loss: 0.0403\n",
      "----------\n",
      "epoch 91/100\n",
      "1/2, train_loss: 0.0416, time taken: 5.604612827301025s\n",
      "2/2, train_loss: 0.0408, time taken: 1.074387788772583s\n",
      "3/2, train_loss: 0.0307, time taken: 0.8185887336730957s\n",
      "epoch 91 average loss: 0.0377\n",
      "Entering Validation for epoch: 91\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 91 Validation avg loss: 0.0105, time taken: 0.20525336265563965s\n",
      "Saving new model based on validation loss 0.0105\n",
      "----------\n",
      "epoch 92/100\n",
      "1/2, train_loss: 0.0388, time taken: 5.38318943977356s\n",
      "2/2, train_loss: 0.0383, time taken: 0.9998078346252441s\n",
      "3/2, train_loss: 0.0283, time taken: 0.7949211597442627s\n",
      "epoch 92 average loss: 0.0351\n",
      "----------\n",
      "epoch 93/100\n",
      "1/2, train_loss: 0.0362, time taken: 5.745938777923584s\n",
      "2/2, train_loss: 0.0346, time taken: 0.9915125370025635s\n",
      "3/2, train_loss: 0.0260, time taken: 0.8005497455596924s\n",
      "epoch 93 average loss: 0.0323\n",
      "Entering Validation for epoch: 93\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 93 Validation avg loss: 0.0088, time taken: 0.2659730911254883s\n",
      "Saving new model based on validation loss 0.0088\n",
      "----------\n",
      "epoch 94/100\n",
      "1/2, train_loss: 0.0328, time taken: 5.49324107170105s\n",
      "2/2, train_loss: 0.0318, time taken: 1.1896276473999023s\n",
      "3/2, train_loss: 0.0238, time taken: 0.8067295551300049s\n",
      "epoch 94 average loss: 0.0295\n",
      "----------\n",
      "epoch 95/100\n",
      "1/2, train_loss: 0.0296, time taken: 5.389276742935181s\n",
      "2/2, train_loss: 0.0298, time taken: 1.4069349765777588s\n",
      "3/2, train_loss: 0.0219, time taken: 0.7872567176818848s\n",
      "epoch 95 average loss: 0.0271\n",
      "Entering Validation for epoch: 95\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 95 Validation avg loss: 0.0077, time taken: 0.20357108116149902s\n",
      "Saving new model based on validation loss 0.0077\n",
      "----------\n",
      "epoch 96/100\n",
      "1/2, train_loss: 0.0286, time taken: 5.119992256164551s\n",
      "2/2, train_loss: 0.0279, time taken: 1.0688836574554443s\n",
      "3/2, train_loss: 0.0208, time taken: 0.7375648021697998s\n",
      "epoch 96 average loss: 0.0258\n",
      "----------\n",
      "epoch 97/100\n",
      "1/2, train_loss: 0.0269, time taken: 5.584094285964966s\n",
      "2/2, train_loss: 0.0258, time taken: 0.9019646644592285s\n",
      "3/2, train_loss: 0.0196, time taken: 1.390657901763916s\n",
      "epoch 97 average loss: 0.0241\n",
      "Entering Validation for epoch: 97\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 97 Validation avg loss: 0.0067, time taken: 0.18585467338562012s\n",
      "Saving new model based on validation loss 0.0067\n",
      "----------\n",
      "epoch 98/100\n",
      "1/2, train_loss: 0.0248, time taken: 5.900523662567139s\n",
      "2/2, train_loss: 0.0239, time taken: 1.1090710163116455s\n",
      "3/2, train_loss: 0.0175, time taken: 1.106999397277832s\n",
      "epoch 98 average loss: 0.0221\n",
      "----------\n",
      "epoch 99/100\n",
      "1/2, train_loss: 0.0221, time taken: 4.9078004360198975s\n",
      "2/2, train_loss: 0.0209, time taken: 0.8875174522399902s\n",
      "3/2, train_loss: 0.0160, time taken: 0.7771568298339844s\n",
      "epoch 99 average loss: 0.0197\n",
      "Entering Validation for epoch: 99\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([8, 1, 32, 32, 32])\n",
      "Input shape: torch.Size([4, 1, 32, 32, 32])\n",
      "epoch 99 Validation avg loss: 0.0054, time taken: 0.2122335433959961s\n",
      "Saving new model based on validation loss 0.0054\n",
      "----------\n",
      "epoch 100/100\n",
      "1/2, train_loss: 0.0198, time taken: 5.546471118927002s\n",
      "2/2, train_loss: 0.0196, time taken: 0.9042563438415527s\n",
      "3/2, train_loss: 0.0141, time taken: 0.8078329563140869s\n",
      "epoch 100 average loss: 0.0178\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_cl_loss = 0\n",
    "    epoch_recon_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        start_time = time.time()\n",
    "\n",
    "        inputs, inputs_2, gt_input = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"image_2\"].to(device),\n",
    "            batch_data[\"gt_image\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs_v1, hidden_v1 = model(inputs)\n",
    "        outputs_v2, hidden_v2 = model(inputs_2)\n",
    "\n",
    "        flat_out_v1 = outputs_v1.flatten(start_dim=1, end_dim=4)\n",
    "        flat_out_v2 = outputs_v2.flatten(start_dim=1, end_dim=4)\n",
    "\n",
    "        r_loss = recon_loss(outputs_v1, gt_input)\n",
    "        cl_loss = contrastive_loss(flat_out_v1, flat_out_v2)\n",
    "\n",
    "        # Adjust the CL loss by Recon Loss\n",
    "        total_loss = r_loss + cl_loss * r_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += total_loss.item()\n",
    "        step_loss_values.append(total_loss.item())\n",
    "\n",
    "        # CL & Recon Loss Storage of Value\n",
    "        epoch_cl_loss += cl_loss.item()\n",
    "        epoch_recon_loss += r_loss.item()\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {total_loss.item():.4f}, \"\n",
    "            f\"time taken: {end_time-start_time}s\"\n",
    "        )\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_cl_loss /= step\n",
    "    epoch_recon_loss /= step\n",
    "\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    epoch_cl_loss_values.append(epoch_cl_loss)\n",
    "    epoch_recon_loss_values.append(epoch_recon_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if epoch % val_interval == 0:\n",
    "        print(\"Entering Validation for epoch: {}\".format(epoch + 1))\n",
    "        total_val_loss = 0\n",
    "        val_step = 0\n",
    "        model.eval()\n",
    "        for val_batch in val_loader:\n",
    "            val_step += 1\n",
    "            start_time = time.time()\n",
    "            inputs, gt_input = (\n",
    "                val_batch[\"image\"].to(device),\n",
    "                val_batch[\"gt_image\"].to(device),\n",
    "            )\n",
    "            print(\"Input shape: {}\".format(inputs.shape))\n",
    "            outputs, outputs_v2 = model(inputs)\n",
    "            val_loss = recon_loss(outputs, gt_input)\n",
    "            total_val_loss += val_loss.item()\n",
    "            end_time = time.time()\n",
    "\n",
    "        total_val_loss /= val_step\n",
    "        val_loss_values.append(total_val_loss)\n",
    "        print(\n",
    "            f\"epoch {epoch + 1} Validation avg loss: {total_val_loss:.4f}, \" f\"time taken: {end_time-start_time}s\")\n",
    "\n",
    "        if total_val_loss < best_val_loss:\n",
    "            print(\n",
    "                f\"Saving new model based on validation loss {total_val_loss:.4f}\")\n",
    "            best_val_loss = total_val_loss\n",
    "            checkpoint = {\"epoch\": max_epochs, \"state_dict\": model.state_dict(\n",
    "            ), \"optimizer\": optimizer.state_dict()}\n",
    "            torch.save(checkpoint, os.path.join(logdir_path, \"best_model_Synth.pt\"))\n",
    "\n",
    "        plt.figure(1, figsize=(8, 8))\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(epoch_loss_values)\n",
    "        plt.grid()\n",
    "        plt.title(\"Training Loss\")\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(val_loss_values)\n",
    "        plt.grid()\n",
    "        plt.title(\"Validation Loss\")\n",
    "\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(epoch_cl_loss_values)\n",
    "        plt.grid()\n",
    "        plt.title(\"Training Contrastive Loss\")\n",
    "\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(epoch_recon_loss_values)\n",
    "        plt.grid()\n",
    "        plt.title(\"Training Recon Loss\")\n",
    "\n",
    "        plt.savefig(os.path.join(logdir_path, \"loss_plots.png\"))\n",
    "        plt.close(1)\n",
    "\n",
    "print(\"Done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
