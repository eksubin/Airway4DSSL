{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.4.dev2414\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.2.2+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 5b248f6a0dd29cb9c2a9545f980a88de16a6b753\n",
      "MONAI __file__: /home/<username>/virtenvs/SSLUnet/lib/python3.11/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.22.0\n",
      "scipy version: 1.13.0\n",
      "Pillow version: 10.3.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "einops version: 0.7.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.config import print_config\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    EnsureChannelFirstd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    ToTensord,\n",
    "    Resized\n",
    ")\n",
    "\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the file input and output locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logdir = os.path.normpath(\"./logs/fine/\")\n",
    "\n",
    "if os.path.exists(logdir) is False:\n",
    "    os.mkdir(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load the pre-trained model\n",
    "use_pretrained = True\n",
    "pretrained_path = os.path.normpath(\"./logs/best_model_32.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image': './Synth3DVal/im0.nii.gz', 'label': './Synth3DVal/seg0.nii.gz'}, {'image': './Synth3DVal/im1.nii.gz', 'label': './Synth3DVal/seg1.nii.gz'}, {'image': './Synth3DVal/im2.nii.gz', 'label': './Synth3DVal/seg2.nii.gz'}, {'image': './Synth3DVal/im3.nii.gz', 'label': './Synth3DVal/seg3.nii.gz'}, {'image': './Synth3DVal/im4.nii.gz', 'label': './Synth3DVal/seg4.nii.gz'}, {'image': './Synth3DVal/im5.nii.gz', 'label': './Synth3DVal/seg5.nii.gz'}, {'image': './Synth3DVal/im6.nii.gz', 'label': './Synth3DVal/seg6.nii.gz'}, {'image': './Synth3DVal/im7.nii.gz', 'label': './Synth3DVal/seg7.nii.gz'}, {'image': './Synth3DVal/im8.nii.gz', 'label': './Synth3DVal/seg8.nii.gz'}, {'image': './Synth3DVal/im9.nii.gz', 'label': './Synth3DVal/seg9.nii.gz'}] [{'image': './Synth3DVal/im0.nii.gz', 'label': './Synth3DVal/seg0.nii.gz'}, {'image': './Synth3DVal/im1.nii.gz', 'label': './Synth3DVal/seg1.nii.gz'}, {'image': './Synth3DVal/im2.nii.gz', 'label': './Synth3DVal/seg2.nii.gz'}, {'image': './Synth3DVal/im3.nii.gz', 'label': './Synth3DVal/seg3.nii.gz'}, {'image': './Synth3DVal/im4.nii.gz', 'label': './Synth3DVal/seg4.nii.gz'}, {'image': './Synth3DVal/im5.nii.gz', 'label': './Synth3DVal/seg5.nii.gz'}, {'image': './Synth3DVal/im6.nii.gz', 'label': './Synth3DVal/seg6.nii.gz'}, {'image': './Synth3DVal/im7.nii.gz', 'label': './Synth3DVal/seg7.nii.gz'}, {'image': './Synth3DVal/im8.nii.gz', 'label': './Synth3DVal/seg8.nii.gz'}, {'image': './Synth3DVal/im9.nii.gz', 'label': './Synth3DVal/seg9.nii.gz'}]\n"
     ]
    }
   ],
   "source": [
    "#Convert the train and validation images into a list with locations\n",
    "\n",
    "train_dir = \"./Synth3D\"\n",
    "val_dir = \"./Synth3DVal\"\n",
    "\n",
    "#train image file\n",
    "timage_filenames = sorted([os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.startswith(\"im\")])\n",
    "tlabel_filenames = sorted([os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.startswith(\"seg\")])\n",
    "\n",
    "#validation image files\n",
    "vimage_filenames = sorted([os.path.join(val_dir, f) for f in os.listdir(val_dir) if f.startswith(\"im\")])\n",
    "vlabel_filenames = sorted([os.path.join(val_dir, f) for f in os.listdir(val_dir) if f.startswith(\"seg\")])\n",
    "\n",
    "# Create a list of dictionaries containing the file paths\n",
    "train_datalist = [{\"image\": img, \"label\": lbl} for img, lbl in zip(vimage_filenames, vlabel_filenames)]\n",
    "validation_datalist = [{\"image\": img, \"label\": lbl} for img, lbl in zip(vimage_filenames, vlabel_filenames)]\n",
    "\n",
    "# Print the datalist to verify\n",
    "print(train_datalist, validation_datalist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validation transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Hyper-params\n",
    "lr = 1e-4\n",
    "max_iterations = 50\n",
    "eval_num = 10\n",
    "\n",
    "# Transforms\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # Spacingd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     pixdim=(1.5, 1.5, 4.0),\n",
    "        #     mode=(\"bilinear\", \"nearest\"),\n",
    "        # ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(32, 32, 32),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,),\n",
    "        # ),\n",
    "        # RandFlipd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     spatial_axis=[0],\n",
    "        #     prob=0.10,\n",
    "        # ),\n",
    "        # RandFlipd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     spatial_axis=[1],\n",
    "        #     prob=0.10,\n",
    "        # ),\n",
    "        # RandFlipd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     spatial_axis=[2],\n",
    "        #     prob=0.10,\n",
    "        # ),\n",
    "        # RandRotate90d(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     prob=0.10,\n",
    "        #     max_k=3,\n",
    "        # ),\n",
    "        # RandShiftIntensityd(\n",
    "        #     keys=[\"image\"],\n",
    "        #     offsets=0.10,\n",
    "        #     prob=0.50,\n",
    "        # ),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Validation transforms\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-175,\n",
    "                             a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 10/10 [00:00<00:00, 61.89it/s]\n",
      "Loading dataset: 100%|██████████| 6/6 [00:00<00:00, 39.55it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ds = CacheDataset(\n",
    "    data=train_datalist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=24,\n",
    "    cache_rate=1.0,\n",
    "    num_workers=2,\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=1,\n",
    "                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_ds = CacheDataset(data=validation_datalist, transform=val_transforms,\n",
    "                      cache_num=6, cache_rate=1.0, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1,\n",
    "                        shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n"
     ]
    }
   ],
   "source": [
    "# just conforming the image sizes for the data inside the folder\n",
    "\n",
    "for case_num in range(len(val_ds)):\n",
    "    img = val_ds[case_num][\"image\"]\n",
    "    label = val_ds[case_num][\"label\"]\n",
    "    img_shape = img.shape\n",
    "    label_shape = label.shape\n",
    "    print(f\"image shape: {img_shape}, label shape: {label_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Weights from the Path logs/best_model_32.pt\n",
      "Pretrained Weights Succesfully Loaded !\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") # current GPU cannot handle this\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=14,\n",
    "    img_size=(32, 32, 32),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"conv\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ")\n",
    "\n",
    "# Load ViT backbone weights into UNETR\n",
    "if use_pretrained is True:\n",
    "    print(\"Loading Weights from the Path {}\".format(pretrained_path))\n",
    "    vit_dict = torch.load(pretrained_path)\n",
    "    vit_weights = vit_dict[\"state_dict\"]\n",
    "    model_dict = model.vit.state_dict()\n",
    "\n",
    "    vit_weights = {k: v for k, v in vit_weights.items() if k in model_dict}\n",
    "    model_dict.update(vit_weights)\n",
    "    model.vit.load_state_dict(model_dict)\n",
    "    del model_dict, vit_weights, vit_dict\n",
    "    print(\"Pretrained Weights Succesfully Loaded !\")\n",
    "\n",
    "elif use_pretrained is False:\n",
    "    print(\"No weights were loaded, all weights being used are randomly initialized!\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "post_label = AsDiscrete(to_onehot=14)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=14)\n",
    "dice_metric = DiceMetric(include_background=True,\n",
    "                         reduction=\"mean\", get_not_nans=False)\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (9 / 50 Steps) (loss=3.61612): 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Training (10 / 50 Steps) (loss=3.59708):   0%|          | 0/10 [00:05<?, ?it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07279):   0%|          | 0/10 [00:01<?, ?it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07279):  10%|█         | 1/10 [00:01<00:09,  1.01s/it]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07169):  10%|█         | 1/10 [00:01<00:09,  1.01s/it]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07169):  20%|██        | 2/10 [00:01<00:04,  1.84it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07425):  20%|██        | 2/10 [00:01<00:04,  1.84it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07425):  30%|███       | 3/10 [00:01<00:02,  2.63it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07504):  30%|███       | 3/10 [00:01<00:02,  2.63it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07504):  40%|████      | 4/10 [00:01<00:01,  3.34it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07385):  40%|████      | 4/10 [00:01<00:01,  3.34it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07385):  50%|█████     | 5/10 [00:01<00:01,  4.24it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07450):  50%|█████     | 5/10 [00:01<00:01,  4.24it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07450):  60%|██████    | 6/10 [00:01<00:00,  4.70it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07412):  60%|██████    | 6/10 [00:01<00:00,  4.70it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07412):  70%|███████   | 7/10 [00:01<00:00,  5.49it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07189):  70%|███████   | 7/10 [00:02<00:00,  5.49it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07189):  80%|████████  | 8/10 [00:02<00:00,  6.17it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07153):  80%|████████  | 8/10 [00:02<00:00,  6.17it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07153):  90%|█████████ | 9/10 [00:02<00:00,  6.07it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07159):  90%|█████████ | 9/10 [00:02<00:00,  6.07it/s]\u001b[A\n",
      "Validate (10 / 10 Steps) (dice=0.07159): 100%|██████████| 10/10 [00:02<00:00,  3.78it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.07312348634004592 Current Avg. Dice: 0.07312348634004592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (19 / 50 Steps) (loss=3.48405): 100%|██████████| 10/10 [00:13<00:00,  1.38s/it]\n",
      "Training (20 / 50 Steps) (loss=3.43219):   0%|          | 0/10 [00:04<?, ?it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.23837):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.23837):  10%|█         | 1/10 [00:00<00:08,  1.02it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24275):  10%|█         | 1/10 [00:01<00:08,  1.02it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24275):  20%|██        | 2/10 [00:01<00:04,  1.75it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24249):  20%|██        | 2/10 [00:01<00:04,  1.75it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24249):  30%|███       | 3/10 [00:01<00:02,  2.46it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24354):  30%|███       | 3/10 [00:01<00:02,  2.46it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24354):  40%|████      | 4/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24225):  40%|████      | 4/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24225):  50%|█████     | 5/10 [00:01<00:01,  3.97it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24177):  50%|█████     | 5/10 [00:01<00:01,  3.97it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24177):  60%|██████    | 6/10 [00:01<00:00,  4.40it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24243):  60%|██████    | 6/10 [00:02<00:00,  4.40it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.24243):  70%|███████   | 7/10 [00:02<00:00,  5.16it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.23937):  70%|███████   | 7/10 [00:02<00:00,  5.16it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.23937):  80%|████████  | 8/10 [00:02<00:00,  5.31it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.23984):  80%|████████  | 8/10 [00:02<00:00,  5.31it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.23984):  90%|█████████ | 9/10 [00:02<00:00,  5.92it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.23913):  90%|█████████ | 9/10 [00:02<00:00,  5.92it/s]\u001b[A\n",
      "Validate (20 / 10 Steps) (dice=0.23913): 100%|██████████| 10/10 [00:02<00:00,  3.61it/s]\u001b[A\n",
      "Training (20 / 50 Steps) (loss=3.43219):  10%|█         | 1/10 [00:09<01:22,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.24119106233119963 Current Avg. Dice: 0.24119106233119963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (29 / 50 Steps) (loss=3.34659): 100%|██████████| 10/10 [00:14<00:00,  1.40s/it]\n",
      "Training (30 / 50 Steps) (loss=3.32284):   0%|          | 0/10 [00:04<?, ?it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42039):   0%|          | 0/10 [00:01<?, ?it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42039):  10%|█         | 1/10 [00:01<00:09,  1.07s/it]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.43134):  10%|█         | 1/10 [00:01<00:09,  1.07s/it]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.43134):  20%|██        | 2/10 [00:01<00:04,  1.74it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42768):  20%|██        | 2/10 [00:01<00:04,  1.74it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42768):  30%|███       | 3/10 [00:01<00:02,  2.48it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.43007):  30%|███       | 3/10 [00:01<00:02,  2.48it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.43007):  40%|████      | 4/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42984):  40%|████      | 4/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42984):  50%|█████     | 5/10 [00:01<00:01,  4.06it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42781):  50%|█████     | 5/10 [00:01<00:01,  4.06it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42781):  60%|██████    | 6/10 [00:01<00:00,  4.50it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42952):  60%|██████    | 6/10 [00:02<00:00,  4.50it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42952):  70%|███████   | 7/10 [00:02<00:00,  5.26it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42767):  70%|███████   | 7/10 [00:02<00:00,  5.26it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42767):  80%|████████  | 8/10 [00:02<00:00,  5.35it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42889):  80%|████████  | 8/10 [00:02<00:00,  5.35it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42889):  90%|█████████ | 9/10 [00:02<00:00,  6.08it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42615):  90%|█████████ | 9/10 [00:02<00:00,  6.08it/s]\u001b[A\n",
      "Validate (30 / 10 Steps) (dice=0.42615): 100%|██████████| 10/10 [00:02<00:00,  3.55it/s]\u001b[A\n",
      "Training (30 / 50 Steps) (loss=3.32284):  10%|█         | 1/10 [00:09<01:22,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.42793580889701843 Current Avg. Dice: 0.42793580889701843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (39 / 50 Steps) (loss=3.14329): 100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n",
      "Training (40 / 50 Steps) (loss=3.16704):   0%|          | 0/10 [00:05<?, ?it/s]\n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.57158):   0%|          | 0/10 [00:01<?, ?it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.57158):  10%|█         | 1/10 [00:01<00:10,  1.12s/it]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58305):  10%|█         | 1/10 [00:01<00:10,  1.12s/it]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58305):  20%|██        | 2/10 [00:01<00:05,  1.56it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58181):  20%|██        | 2/10 [00:01<00:05,  1.56it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58181):  30%|███       | 3/10 [00:01<00:03,  2.30it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58490):  30%|███       | 3/10 [00:01<00:03,  2.30it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58490):  40%|████      | 4/10 [00:01<00:02,  2.98it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58455):  40%|████      | 4/10 [00:01<00:02,  2.98it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58455):  50%|█████     | 5/10 [00:01<00:01,  3.54it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58236):  50%|█████     | 5/10 [00:02<00:01,  3.54it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58236):  60%|██████    | 6/10 [00:02<00:00,  4.38it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58347):  60%|██████    | 6/10 [00:02<00:00,  4.38it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58347):  70%|███████   | 7/10 [00:02<00:00,  4.69it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58092):  70%|███████   | 7/10 [00:02<00:00,  4.69it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58092):  80%|████████  | 8/10 [00:02<00:00,  5.46it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58176):  80%|████████  | 8/10 [00:02<00:00,  5.46it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58176):  90%|█████████ | 9/10 [00:02<00:00,  5.53it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58016):  90%|█████████ | 9/10 [00:02<00:00,  5.53it/s]\u001b[A\n",
      "Validate (40 / 10 Steps) (dice=0.58016): 100%|██████████| 10/10 [00:02<00:00,  3.34it/s]\u001b[A\n",
      "Training (40 / 50 Steps) (loss=3.16704):  10%|█         | 1/10 [00:09<01:26,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.5814559459686279 Current Avg. Dice: 0.5814559459686279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (49 / 50 Steps) (loss=3.01787): 100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train completed, best_metric: 0.5815 at iteration: 40\n"
     ]
    }
   ],
   "source": [
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    dice_vals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _step, batch in enumerate(epoch_iterator_val):\n",
    "            val_inputs, val_labels = (\n",
    "                batch[\"image\"], batch[\"label\"])\n",
    "            val_outputs = sliding_window_inference(\n",
    "                val_inputs, (32, 32, 32), 4, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(\n",
    "                val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor)\n",
    "                                  for val_pred_tensor in val_outputs_list]\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            dice = dice_metric.aggregate().item()\n",
    "            dice_vals.append(dice)\n",
    "            epoch_iterator_val.set_description(\n",
    "                \"Validate (%d / %d Steps) (dice=%2.5f)\" % (global_step, 10.0, dice))\n",
    "\n",
    "        dice_metric.reset()\n",
    "\n",
    "    mean_dice_val = np.mean(dice_vals)\n",
    "    return mean_dice_val\n",
    "\n",
    "\n",
    "def train(global_step, train_loader, dice_val_best, global_step_best):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(\n",
    "        train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True)\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        x, y = (batch[\"image\"], batch[\"label\"])\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iterator.set_description(\n",
    "            \"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss))\n",
    "\n",
    "        if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
    "            epoch_iterator_val = tqdm(\n",
    "                val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "            dice_val = validation(epoch_iterator_val)\n",
    "\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            metric_values.append(dice_val)\n",
    "            if dice_val > dice_val_best:\n",
    "                dice_val_best = dice_val\n",
    "                global_step_best = global_step\n",
    "                torch.save(model.state_dict(), os.path.join(\n",
    "                    logdir, \"best_metric_model.pth\"))\n",
    "                print(\n",
    "                    \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val)\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            plt.figure(1, (12, 6))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.title(\"Iteration Average Loss\")\n",
    "            x = [eval_num * (i + 1) for i in range(len(epoch_loss_values))]\n",
    "            y = epoch_loss_values\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.plot(x, y)\n",
    "            plt.grid()\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.title(\"Val Mean Dice\")\n",
    "            x = [eval_num * (i + 1) for i in range(len(metric_values))]\n",
    "            y = metric_values\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.plot(x, y)\n",
    "            plt.grid()\n",
    "            plt.savefig(os.path.join(logdir, \"btcv_finetune_quick_update.png\"))\n",
    "            plt.clf()\n",
    "            plt.close(1)\n",
    "\n",
    "        global_step += 1\n",
    "    return global_step, dice_val_best, global_step_best\n",
    "\n",
    "\n",
    "while global_step < max_iterations:\n",
    "    global_step, dice_val_best, global_step_best = train(\n",
    "        global_step, train_loader, dice_val_best, global_step_best)\n",
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(logdir, \"best_metric_model.pth\")))\n",
    "\n",
    "print(\n",
    "    f\"train completed, best_metric: {dice_val_best:.4f} \" f\"at iteration: {global_step_best}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.4.dev2414\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.2.2+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 5b248f6a0dd29cb9c2a9545f980a88de16a6b753\n",
      "MONAI __file__: /home/<username>/virtenvs/SSLUnet/lib/python3.11/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.22.0\n",
      "scipy version: 1.13.0\n",
      "Pillow version: 10.3.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "einops version: 0.7.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, Spacingd,\n",
    "    ScaleIntensityRanged, CropForegroundd, RandCropByPosNegLabeld, ToTensord\n",
    ")\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.config import print_config\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed image shape: torch.Size([1, 1, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# printing the results\n",
    "\n",
    "# Define the transformation pipeline for the single image\n",
    "single_image_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"], reader=\"nrrdreader\"),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Spacingd(\n",
    "            keys=[\"image\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-200,\n",
    "            a_max=200,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "        ToTensord(keys=[\"image\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Example NRRD file path\n",
    "image_file = \"./Synth3DVal/im0.nii.gz\"\n",
    "\n",
    "# Create a dictionary for the single image\n",
    "single_image_data = [{\"image\": image_file}]\n",
    "\n",
    "# Create a Dataset for the single image\n",
    "single_image_ds = Dataset(data=single_image_data, transform=single_image_transforms)\n",
    "\n",
    "# Load and preprocess the image\n",
    "single_image_loader = DataLoader(single_image_ds, batch_size=1)\n",
    "single_image_batch = next(iter(single_image_loader))\n",
    "single_image = single_image_batch[\"image\"]\n",
    "\n",
    "# Print the shape of the preprocessed image\n",
    "print(f\"Preprocessed image shape: {single_image.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation output shape: (1, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# Define the model (for example, UNet)\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=14,\n",
    "    img_size=(32, 32, 32),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"conv\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").cuda()\n",
    "\n",
    "# Load pre-trained model weights (modify the path as needed)\n",
    "model.load_state_dict(torch.load(\"./logs/fine/best_metric_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    single_image = single_image.cuda()\n",
    "    output = sliding_window_inference(single_image, roi_size=(32, 32, 32), sw_batch_size=1, predictor=model)\n",
    "\n",
    "# Convert the output to a binary mask\n",
    "output = torch.argmax(output, dim=1).cpu().numpy()\n",
    "print(f\"Segmentation output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract a slice from the input image and the segmentation output\n",
    "slice = 20\n",
    "\n",
    "input_slice = single_image[0, 0, :, :, slice].cpu().numpy()  # Extracting slice 16\n",
    "output_slice = output[0, :, :, slice]  # Extracting the same slice from the output\n",
    "\n",
    "# Visualize input and output as subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Input image subplot\n",
    "axes[0].imshow(input_slice, cmap=\"gray\")\n",
    "axes[0].set_title(\"Input Image (Slice 16)\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Segmentation output subplot\n",
    "axes[1].imshow(output_slice, cmap=\"gray\")\n",
    "axes[1].set_title(\"Segmentation Output (Slice 16)\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSLUnet",
   "language": "python",
   "name": "sslunet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
