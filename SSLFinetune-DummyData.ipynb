{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.2.2+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: /home/<username>/.conda/envs/unetSSL/lib/python3.11/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scipy version: 1.12.0\n",
      "Pillow version: 10.3.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.2.1\n",
      "einops version: 0.8.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.config import print_config\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    EnsureChannelFirstd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    ToTensord,\n",
    "    Resized\n",
    ")\n",
    "\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the file input and output locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logdir = os.path.normpath(\"./logs/fine/\")\n",
    "\n",
    "if os.path.exists(logdir) is False:\n",
    "    os.mkdir(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load the pre-trained model\n",
    "use_pretrained = True\n",
    "pretrained_path = os.path.normpath(\"./logs/best_model_Synth.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image': './Synth3DVal/im0.nii.gz', 'label': './Synth3DVal/seg0.nii.gz'}, {'image': './Synth3DVal/im1.nii.gz', 'label': './Synth3DVal/seg1.nii.gz'}, {'image': './Synth3DVal/im2.nii.gz', 'label': './Synth3DVal/seg2.nii.gz'}, {'image': './Synth3DVal/im3.nii.gz', 'label': './Synth3DVal/seg3.nii.gz'}, {'image': './Synth3DVal/im4.nii.gz', 'label': './Synth3DVal/seg4.nii.gz'}, {'image': './Synth3DVal/im5.nii.gz', 'label': './Synth3DVal/seg5.nii.gz'}, {'image': './Synth3DVal/im6.nii.gz', 'label': './Synth3DVal/seg6.nii.gz'}, {'image': './Synth3DVal/im7.nii.gz', 'label': './Synth3DVal/seg7.nii.gz'}, {'image': './Synth3DVal/im8.nii.gz', 'label': './Synth3DVal/seg8.nii.gz'}, {'image': './Synth3DVal/im9.nii.gz', 'label': './Synth3DVal/seg9.nii.gz'}] [{'image': './Synth3DVal/im0.nii.gz', 'label': './Synth3DVal/seg0.nii.gz'}, {'image': './Synth3DVal/im1.nii.gz', 'label': './Synth3DVal/seg1.nii.gz'}, {'image': './Synth3DVal/im2.nii.gz', 'label': './Synth3DVal/seg2.nii.gz'}, {'image': './Synth3DVal/im3.nii.gz', 'label': './Synth3DVal/seg3.nii.gz'}, {'image': './Synth3DVal/im4.nii.gz', 'label': './Synth3DVal/seg4.nii.gz'}, {'image': './Synth3DVal/im5.nii.gz', 'label': './Synth3DVal/seg5.nii.gz'}, {'image': './Synth3DVal/im6.nii.gz', 'label': './Synth3DVal/seg6.nii.gz'}, {'image': './Synth3DVal/im7.nii.gz', 'label': './Synth3DVal/seg7.nii.gz'}, {'image': './Synth3DVal/im8.nii.gz', 'label': './Synth3DVal/seg8.nii.gz'}, {'image': './Synth3DVal/im9.nii.gz', 'label': './Synth3DVal/seg9.nii.gz'}]\n"
     ]
    }
   ],
   "source": [
    "#Convert the train and validation images into a list with locations\n",
    "\n",
    "train_dir = \"./Synth3D\"\n",
    "val_dir = \"./Synth3DVal\"\n",
    "\n",
    "#train image file\n",
    "timage_filenames = sorted([os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.startswith(\"im\")])\n",
    "tlabel_filenames = sorted([os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.startswith(\"seg\")])\n",
    "\n",
    "#validation image files\n",
    "vimage_filenames = sorted([os.path.join(val_dir, f) for f in os.listdir(val_dir) if f.startswith(\"im\")])\n",
    "vlabel_filenames = sorted([os.path.join(val_dir, f) for f in os.listdir(val_dir) if f.startswith(\"seg\")])\n",
    "\n",
    "# Create a list of dictionaries containing the file paths\n",
    "train_datalist = [{\"image\": img, \"label\": lbl} for img, lbl in zip(vimage_filenames, vlabel_filenames)]\n",
    "validation_datalist = [{\"image\": img, \"label\": lbl} for img, lbl in zip(vimage_filenames, vlabel_filenames)]\n",
    "\n",
    "# Print the datalist to verify\n",
    "print(train_datalist, validation_datalist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validation transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Hyper-params\n",
    "lr = 1e-4\n",
    "max_iterations = 1000\n",
    "eval_num = 100\n",
    "\n",
    "# Transforms\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # Spacingd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     pixdim=(1.5, 1.5, 4.0),\n",
    "        #     mode=(\"bilinear\", \"nearest\"),\n",
    "        # ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(32, 32, 32),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,),\n",
    "        # ),\n",
    "        # RandFlipd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     spatial_axis=[0],\n",
    "        #     prob=0.10,\n",
    "        # ),\n",
    "        # RandFlipd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     spatial_axis=[1],\n",
    "        #     prob=0.10,\n",
    "        # ),\n",
    "        # RandFlipd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     spatial_axis=[2],\n",
    "        #     prob=0.10,\n",
    "        # ),\n",
    "        # RandRotate90d(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     prob=0.10,\n",
    "        #     max_k=3,\n",
    "        # ),\n",
    "        # RandShiftIntensityd(\n",
    "        #     keys=[\"image\"],\n",
    "        #     offsets=0.10,\n",
    "        #     prob=0.50,\n",
    "        # ),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Validation transforms\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-175,\n",
    "                             a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 10/10 [00:00<00:00, 71.09it/s]\n",
      "Loading dataset: 100%|██████████| 6/6 [00:00<00:00, 49.09it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ds = CacheDataset(\n",
    "    data=train_datalist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=24,\n",
    "    cache_rate=1.0,\n",
    "    num_workers=2,\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=1,\n",
    "                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_ds = CacheDataset(data=validation_datalist, transform=val_transforms,\n",
    "                      cache_num=6, cache_rate=1.0, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1,\n",
    "                        shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n",
      "image shape: torch.Size([1, 43, 43, 32]), label shape: torch.Size([1, 43, 43, 32])\n"
     ]
    }
   ],
   "source": [
    "# just conforming the image sizes for the data inside the folder\n",
    "\n",
    "for case_num in range(len(val_ds)):\n",
    "    img = val_ds[case_num][\"image\"]\n",
    "    label = val_ds[case_num][\"label\"]\n",
    "    img_shape = img.shape\n",
    "    label_shape = label.shape\n",
    "    print(f\"image shape: {img_shape}, label shape: {label_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Weights from the Path logs/best_model_Synth.pt\n",
      "Pretrained Weights Succesfully Loaded !\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") # current GPU cannot handle this\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=14,\n",
    "    img_size=(32, 32, 32),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"conv\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ")\n",
    "\n",
    "# Load ViT backbone weights into UNETR\n",
    "if use_pretrained is True:\n",
    "    print(\"Loading Weights from the Path {}\".format(pretrained_path))\n",
    "    vit_dict = torch.load(pretrained_path)\n",
    "    vit_weights = vit_dict[\"state_dict\"]\n",
    "    model_dict = model.vit.state_dict()\n",
    "\n",
    "    vit_weights = {k: v for k, v in vit_weights.items() if k in model_dict}\n",
    "    model_dict.update(vit_weights)\n",
    "    model.vit.load_state_dict(model_dict)\n",
    "    del model_dict, vit_weights, vit_dict\n",
    "    print(\"Pretrained Weights Succesfully Loaded !\")\n",
    "\n",
    "elif use_pretrained is False:\n",
    "    print(\"No weights were loaded, all weights being used are randomly initialized!\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "post_label = AsDiscrete(to_onehot=14)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=14)\n",
    "dice_metric = DiceMetric(include_background=True,\n",
    "                         reduction=\"mean\", get_not_nans=False)\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (9 / 1000 Steps) (loss=3.77467): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Training (19 / 1000 Steps) (loss=3.55418): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Training (29 / 1000 Steps) (loss=3.38290): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Training (39 / 1000 Steps) (loss=3.15335): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Training (49 / 1000 Steps) (loss=3.06552): 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n",
      "Training (59 / 1000 Steps) (loss=2.98071): 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n",
      "Training (69 / 1000 Steps) (loss=3.03393): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (79 / 1000 Steps) (loss=3.02441): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Training (89 / 1000 Steps) (loss=2.86773): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (99 / 1000 Steps) (loss=2.81836): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Validate (100 / 10 Steps) (dice=0.83033): 100%|██████████| 10/10 [00:02<00:00,  4.14it/s]\n",
      "Training (100 / 1000 Steps) (loss=2.83277):  10%|█         | 1/10 [00:09<01:25,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.8356201827526093 Current Avg. Dice: 0.8356201827526093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (109 / 1000 Steps) (loss=2.78542): 100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\n",
      "Training (119 / 1000 Steps) (loss=2.87331): 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Training (129 / 1000 Steps) (loss=2.73505): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (139 / 1000 Steps) (loss=2.69794): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (149 / 1000 Steps) (loss=2.74292): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Training (159 / 1000 Steps) (loss=2.65695): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Training (169 / 1000 Steps) (loss=2.62646): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Training (179 / 1000 Steps) (loss=2.66781): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (189 / 1000 Steps) (loss=2.65526): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (199 / 1000 Steps) (loss=2.65552): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Validate (200 / 10 Steps) (dice=0.91292): 100%|██████████| 10/10 [00:02<00:00,  3.86it/s]\n",
      "Training (200 / 1000 Steps) (loss=2.58853):  10%|█         | 1/10 [00:09<01:24,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.9178534805774688 Current Avg. Dice: 0.9178534805774688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (209 / 1000 Steps) (loss=2.53547): 100%|██████████| 10/10 [00:14<00:00,  1.42s/it]\n",
      "Training (219 / 1000 Steps) (loss=2.52948): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Training (229 / 1000 Steps) (loss=2.64043): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Training (239 / 1000 Steps) (loss=2.46247): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (249 / 1000 Steps) (loss=2.38426): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (259 / 1000 Steps) (loss=2.48719): 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Training (269 / 1000 Steps) (loss=2.34284): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (279 / 1000 Steps) (loss=2.36275): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Training (289 / 1000 Steps) (loss=2.33739): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (299 / 1000 Steps) (loss=2.32279): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Validate (300 / 10 Steps) (dice=0.95347): 100%|██████████| 10/10 [00:02<00:00,  3.97it/s]\n",
      "Training (300 / 1000 Steps) (loss=2.31342):  10%|█         | 1/10 [00:09<01:22,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.9570350289344788 Current Avg. Dice: 0.9570350289344788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (309 / 1000 Steps) (loss=2.31365): 100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\n",
      "Training (319 / 1000 Steps) (loss=2.25183): 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Training (329 / 1000 Steps) (loss=2.35135): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Training (339 / 1000 Steps) (loss=2.17313): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (349 / 1000 Steps) (loss=2.19764): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Training (359 / 1000 Steps) (loss=2.16438): 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n",
      "Training (369 / 1000 Steps) (loss=2.10878): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (379 / 1000 Steps) (loss=2.08238): 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n",
      "Training (389 / 1000 Steps) (loss=2.30812): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (399 / 1000 Steps) (loss=2.15766): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Validate (400 / 10 Steps) (dice=0.97148): 100%|██████████| 10/10 [00:02<00:00,  3.91it/s]\n",
      "Training (400 / 1000 Steps) (loss=2.04184):  10%|█         | 1/10 [00:09<01:24,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.974016296863556 Current Avg. Dice: 0.974016296863556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (409 / 1000 Steps) (loss=2.05548): 100%|██████████| 10/10 [00:13<00:00,  1.36s/it]\n",
      "Training (419 / 1000 Steps) (loss=2.12617): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (429 / 1000 Steps) (loss=2.23056): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Training (439 / 1000 Steps) (loss=2.02756): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (449 / 1000 Steps) (loss=1.93047): 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Training (459 / 1000 Steps) (loss=1.90241): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (469 / 1000 Steps) (loss=2.02421): 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Training (479 / 1000 Steps) (loss=1.92983): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Training (489 / 1000 Steps) (loss=1.93872): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (499 / 1000 Steps) (loss=1.89028): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Validate (500 / 10 Steps) (dice=0.98462): 100%|██████████| 10/10 [00:02<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.9863553881645203 Current Avg. Dice: 0.9863553881645203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (509 / 1000 Steps) (loss=2.04222): 100%|██████████| 10/10 [00:14<00:00,  1.42s/it]\n",
      "Training (519 / 1000 Steps) (loss=1.87104): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (529 / 1000 Steps) (loss=1.89113): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (539 / 1000 Steps) (loss=1.86856): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (549 / 1000 Steps) (loss=1.84572): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Training (559 / 1000 Steps) (loss=2.01674): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (569 / 1000 Steps) (loss=1.94038): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (579 / 1000 Steps) (loss=1.93835): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Training (589 / 1000 Steps) (loss=2.04085): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (599 / 1000 Steps) (loss=1.83812): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Validate (600 / 10 Steps) (dice=0.98854): 100%|██████████| 10/10 [00:02<00:00,  3.86it/s]\n",
      "Training (600 / 1000 Steps) (loss=1.87733):  10%|█         | 1/10 [00:09<01:24,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.9896176517009735 Current Avg. Dice: 0.9896176517009735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (609 / 1000 Steps) (loss=1.75579): 100%|██████████| 10/10 [00:13<00:00,  1.39s/it]\n",
      "Training (619 / 1000 Steps) (loss=1.74759): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Training (629 / 1000 Steps) (loss=1.63306): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (639 / 1000 Steps) (loss=1.67418): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Training (649 / 1000 Steps) (loss=1.86245): 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n",
      "Training (659 / 1000 Steps) (loss=1.61284): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Training (669 / 1000 Steps) (loss=1.76106): 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Training (679 / 1000 Steps) (loss=1.63319): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (689 / 1000 Steps) (loss=1.58595): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Training (699 / 1000 Steps) (loss=1.76520): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Validate (700 / 10 Steps) (dice=0.98987): 100%|██████████| 10/10 [00:02<00:00,  4.10it/s]\n",
      "Training (700 / 1000 Steps) (loss=1.53664):  10%|█         | 1/10 [00:09<01:22,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.9901890635490418 Current Avg. Dice: 0.9901890635490418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (709 / 1000 Steps) (loss=1.62970): 100%|██████████| 10/10 [00:13<00:00,  1.38s/it]\n",
      "Training (719 / 1000 Steps) (loss=1.53781): 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Training (729 / 1000 Steps) (loss=1.68191): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Training (739 / 1000 Steps) (loss=1.98166): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (749 / 1000 Steps) (loss=1.51267): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Training (759 / 1000 Steps) (loss=1.61666): 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Training (769 / 1000 Steps) (loss=1.53306): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (779 / 1000 Steps) (loss=1.69565): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Training (789 / 1000 Steps) (loss=1.47589): 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Training (799 / 1000 Steps) (loss=1.56345): 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n",
      "Validate (800 / 10 Steps) (dice=0.98989): 100%|██████████| 10/10 [00:02<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.990361487865448 Current Avg. Dice: 0.990361487865448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (809 / 1000 Steps) (loss=1.44748): 100%|██████████| 10/10 [00:14<00:00,  1.50s/it]\n",
      "Training (819 / 1000 Steps) (loss=1.57060): 100%|██████████| 10/10 [00:08<00:00,  1.11it/s]\n",
      "Training (829 / 1000 Steps) (loss=1.71374): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (839 / 1000 Steps) (loss=1.49292): 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Training (849 / 1000 Steps) (loss=1.39832): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (859 / 1000 Steps) (loss=1.39914): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (869 / 1000 Steps) (loss=1.41396): 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Training (879 / 1000 Steps) (loss=1.37503): 100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n",
      "Training (889 / 1000 Steps) (loss=1.30623): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (899 / 1000 Steps) (loss=1.43210): 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Validate (900 / 10 Steps) (dice=0.98998): 100%|██████████| 10/10 [00:02<00:00,  3.80it/s]\n",
      "Training (900 / 1000 Steps) (loss=1.47852):  10%|█         | 1/10 [00:10<01:38, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.9905401825904846 Current Avg. Dice: 0.9905401825904846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (909 / 1000 Steps) (loss=1.37179): 100%|██████████| 10/10 [00:16<00:00,  1.68s/it]\n",
      "Training (919 / 1000 Steps) (loss=1.33153): 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Training (929 / 1000 Steps) (loss=1.40736): 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Training (939 / 1000 Steps) (loss=1.45121): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Training (949 / 1000 Steps) (loss=1.42037): 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Training (959 / 1000 Steps) (loss=1.29181): 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Training (969 / 1000 Steps) (loss=1.29958): 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n",
      "Training (979 / 1000 Steps) (loss=1.36441): 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Training (989 / 1000 Steps) (loss=1.30224): 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Training (999 / 1000 Steps) (loss=1.31501): 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train completed, best_metric: 0.9905 at iteration: 900\n"
     ]
    }
   ],
   "source": [
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    dice_vals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _step, batch in enumerate(epoch_iterator_val):\n",
    "            val_inputs, val_labels = (\n",
    "                batch[\"image\"], batch[\"label\"])\n",
    "            val_outputs = sliding_window_inference(\n",
    "                val_inputs, (32, 32, 32), 4, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(\n",
    "                val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor)\n",
    "                                  for val_pred_tensor in val_outputs_list]\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            dice = dice_metric.aggregate().item()\n",
    "            dice_vals.append(dice)\n",
    "            epoch_iterator_val.set_description(\n",
    "                \"Validate (%d / %d Steps) (dice=%2.5f)\" % (global_step, 10.0, dice))\n",
    "\n",
    "        dice_metric.reset()\n",
    "\n",
    "    mean_dice_val = np.mean(dice_vals)\n",
    "    return mean_dice_val\n",
    "\n",
    "\n",
    "def train(global_step, train_loader, dice_val_best, global_step_best):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(\n",
    "        train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True)\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        x, y = (batch[\"image\"], batch[\"label\"])\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iterator.set_description(\n",
    "            \"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss))\n",
    "\n",
    "        if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
    "            epoch_iterator_val = tqdm(\n",
    "                val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "            dice_val = validation(epoch_iterator_val)\n",
    "\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            metric_values.append(dice_val)\n",
    "            if dice_val > dice_val_best:\n",
    "                dice_val_best = dice_val\n",
    "                global_step_best = global_step\n",
    "                torch.save(model.state_dict(), os.path.join(\n",
    "                    logdir, \"best_metric_model_synth.pth\"))\n",
    "                print(\n",
    "                    \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val)\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            plt.figure(1, (12, 6))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.title(\"Iteration Average Loss\")\n",
    "            x = [eval_num * (i + 1) for i in range(len(epoch_loss_values))]\n",
    "            y = epoch_loss_values\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.plot(x, y)\n",
    "            plt.grid()\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.title(\"Val Mean Dice\")\n",
    "            x = [eval_num * (i + 1) for i in range(len(metric_values))]\n",
    "            y = metric_values\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.plot(x, y)\n",
    "            plt.grid()\n",
    "            plt.savefig(os.path.join(logdir, \"btcv_finetune_quick_update_synth.png\"))\n",
    "            plt.clf()\n",
    "            plt.close(1)\n",
    "\n",
    "        global_step += 1\n",
    "    return global_step, dice_val_best, global_step_best\n",
    "\n",
    "\n",
    "while global_step < max_iterations:\n",
    "    global_step, dice_val_best, global_step_best = train(\n",
    "        global_step, train_loader, dice_val_best, global_step_best)\n",
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(logdir, \"best_metric_model_synth.pth\")))\n",
    "\n",
    "print(\n",
    "    f\"train completed, best_metric: {dice_val_best:.4f} \" f\"at iteration: {global_step_best}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unetSSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
