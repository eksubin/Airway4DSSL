{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.2.2+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: /home/<username>/.conda/envs/unetSSL/lib/python3.11/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scipy version: 1.12.0\n",
      "Pillow version: 10.3.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.2.1\n",
      "einops version: 0.8.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.config import print_config\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    EnsureChannelFirstd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    ToTensord,\n",
    "    Resized\n",
    ")\n",
    "\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the file input and output locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logdir = os.path.normpath(\"./logs/fine/\")\n",
    "\n",
    "if os.path.exists(logdir) is False:\n",
    "    os.mkdir(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load the pre-trained model\n",
    "use_pretrained = True\n",
    "pretrained_path = os.path.normpath(\"./logs/best_model_Synth_500.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image': './Synth3DVal/im0.nii.gz', 'label': './Synth3DVal/seg0.nii.gz'}, {'image': './Synth3DVal/im1.nii.gz', 'label': './Synth3DVal/seg1.nii.gz'}, {'image': './Synth3DVal/im2.nii.gz', 'label': './Synth3DVal/seg2.nii.gz'}, {'image': './Synth3DVal/im3.nii.gz', 'label': './Synth3DVal/seg3.nii.gz'}, {'image': './Synth3DVal/im4.nii.gz', 'label': './Synth3DVal/seg4.nii.gz'}, {'image': './Synth3DVal/im5.nii.gz', 'label': './Synth3DVal/seg5.nii.gz'}, {'image': './Synth3DVal/im6.nii.gz', 'label': './Synth3DVal/seg6.nii.gz'}, {'image': './Synth3DVal/im7.nii.gz', 'label': './Synth3DVal/seg7.nii.gz'}, {'image': './Synth3DVal/im8.nii.gz', 'label': './Synth3DVal/seg8.nii.gz'}, {'image': './Synth3DVal/im9.nii.gz', 'label': './Synth3DVal/seg9.nii.gz'}] [{'image': './Synth3DVal/im0.nii.gz', 'label': './Synth3DVal/seg0.nii.gz'}, {'image': './Synth3DVal/im1.nii.gz', 'label': './Synth3DVal/seg1.nii.gz'}, {'image': './Synth3DVal/im2.nii.gz', 'label': './Synth3DVal/seg2.nii.gz'}, {'image': './Synth3DVal/im3.nii.gz', 'label': './Synth3DVal/seg3.nii.gz'}, {'image': './Synth3DVal/im4.nii.gz', 'label': './Synth3DVal/seg4.nii.gz'}, {'image': './Synth3DVal/im5.nii.gz', 'label': './Synth3DVal/seg5.nii.gz'}, {'image': './Synth3DVal/im6.nii.gz', 'label': './Synth3DVal/seg6.nii.gz'}, {'image': './Synth3DVal/im7.nii.gz', 'label': './Synth3DVal/seg7.nii.gz'}, {'image': './Synth3DVal/im8.nii.gz', 'label': './Synth3DVal/seg8.nii.gz'}, {'image': './Synth3DVal/im9.nii.gz', 'label': './Synth3DVal/seg9.nii.gz'}]\n"
     ]
    }
   ],
   "source": [
    "#Convert the train and validation images into a list with locations\n",
    "\n",
    "train_dir = \"./Synth3D\"\n",
    "val_dir = \"./Synth3DVal\"\n",
    "\n",
    "#train image file\n",
    "timage_filenames = sorted([os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.startswith(\"im\")])\n",
    "tlabel_filenames = sorted([os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.startswith(\"seg\")])\n",
    "\n",
    "#validation image files\n",
    "vimage_filenames = sorted([os.path.join(val_dir, f) for f in os.listdir(val_dir) if f.startswith(\"im\")])\n",
    "vlabel_filenames = sorted([os.path.join(val_dir, f) for f in os.listdir(val_dir) if f.startswith(\"seg\")])\n",
    "\n",
    "# Create a list of dictionaries containing the file paths\n",
    "train_datalist = [{\"image\": img, \"label\": lbl} for img, lbl in zip(vimage_filenames, vlabel_filenames)]\n",
    "validation_datalist = [{\"image\": img, \"label\": lbl} for img, lbl in zip(vimage_filenames, vlabel_filenames)]\n",
    "\n",
    "# Print the datalist to verify\n",
    "print(train_datalist, validation_datalist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validation transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Hyper-params\n",
    "lr = 1e-4\n",
    "max_iterations = 1000\n",
    "eval_num = 100\n",
    "\n",
    "# Transforms\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # Spacingd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     pixdim=(1.5, 1.5, 4.0),\n",
    "        #     mode=(\"bilinear\", \"nearest\"),\n",
    "        # ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(32, 32, 32),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,),\n",
    "        # ),\n",
    "        # RandFlipd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     spatial_axis=[0],\n",
    "        #     prob=0.10,\n",
    "        # ),\n",
    "        # RandFlipd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     spatial_axis=[1],\n",
    "        #     prob=0.10,\n",
    "        # ),\n",
    "        # RandFlipd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     spatial_axis=[2],\n",
    "        #     prob=0.10,\n",
    "        # ),\n",
    "        # RandRotate90d(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     prob=0.10,\n",
    "        #     max_k=3,\n",
    "        # ),\n",
    "        # RandShiftIntensityd(\n",
    "        #     keys=[\"image\"],\n",
    "        #     offsets=0.10,\n",
    "        #     prob=0.50,\n",
    "        # ),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Validation transforms\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # Spacingd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     pixdim=(1.5, 1.5, 2.0),\n",
    "        #     mode=(\"bilinear\", \"nearest\"),\n",
    "        # # ),\n",
    "        # ScaleIntensityRanged(keys=[\"image\"], a_min=-175,\n",
    "        #                      a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 10/10 [00:00<00:00, 63.28it/s]\n",
      "Loading dataset: 100%|██████████| 6/6 [00:00<00:00, 58.52it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ds = CacheDataset(\n",
    "    data=train_datalist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=24,\n",
    "    cache_rate=1.0,\n",
    "    num_workers=2,\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=1,\n",
    "                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_ds = CacheDataset(data=validation_datalist, transform=val_transforms,\n",
    "                      cache_num=6, cache_rate=1.0, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1,\n",
    "                        shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([1, 57, 57, 57]), label shape: torch.Size([1, 57, 57, 57])\n",
      "image shape: torch.Size([1, 57, 55, 55]), label shape: torch.Size([1, 57, 55, 55])\n",
      "image shape: torch.Size([1, 59, 60, 60]), label shape: torch.Size([1, 59, 60, 60])\n",
      "image shape: torch.Size([1, 57, 57, 58]), label shape: torch.Size([1, 57, 57, 58])\n",
      "image shape: torch.Size([1, 53, 53, 53]), label shape: torch.Size([1, 53, 53, 53])\n",
      "image shape: torch.Size([1, 60, 60, 60]), label shape: torch.Size([1, 60, 60, 60])\n",
      "image shape: torch.Size([1, 57, 57, 57]), label shape: torch.Size([1, 57, 57, 57])\n",
      "image shape: torch.Size([1, 45, 46, 45]), label shape: torch.Size([1, 45, 46, 45])\n",
      "image shape: torch.Size([1, 53, 54, 53]), label shape: torch.Size([1, 53, 54, 53])\n",
      "image shape: torch.Size([1, 58, 57, 57]), label shape: torch.Size([1, 58, 57, 57])\n"
     ]
    }
   ],
   "source": [
    "# just conforming the image sizes for the data inside the folder\n",
    "\n",
    "for case_num in range(len(val_ds)):\n",
    "    img = val_ds[case_num][\"image\"]\n",
    "    label = val_ds[case_num][\"label\"]\n",
    "    img_shape = img.shape\n",
    "    label_shape = label.shape\n",
    "    print(f\"image shape: {img_shape}, label shape: {label_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Weights from the Path logs/best_model_Synth_500.pt\n",
      "Pretrained Weights Succesfully Loaded !\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") # current GPU cannot handle this\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    img_size=(32, 32, 32),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"conv\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ")\n",
    "\n",
    "# Load ViT backbone weights into UNETR\n",
    "if use_pretrained is True:\n",
    "    print(\"Loading Weights from the Path {}\".format(pretrained_path))\n",
    "    vit_dict = torch.load(pretrained_path)\n",
    "    vit_weights = vit_dict[\"state_dict\"]\n",
    "    model_dict = model.vit.state_dict()\n",
    "\n",
    "    vit_weights = {k: v for k, v in vit_weights.items() if k in model_dict}\n",
    "    model_dict.update(vit_weights)\n",
    "    model.vit.load_state_dict(model_dict)\n",
    "    del model_dict, vit_weights, vit_dict\n",
    "    print(\"Pretrained Weights Succesfully Loaded !\")\n",
    "\n",
    "elif use_pretrained is False:\n",
    "    print(\"No weights were loaded, all weights being used are randomly initialized!\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "post_label = AsDiscrete(to_onehot=14)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=14)\n",
    "dice_metric = DiceMetric(include_background=True,\n",
    "                         reduction=\"mean\", get_not_nans=False)\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (9 / 1000 Steps) (loss=1.05583): 100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n",
      "Training (19 / 1000 Steps) (loss=0.88059): 100%|██████████| 10/10 [00:18<00:00,  1.88s/it]\n",
      "Training (29 / 1000 Steps) (loss=0.74115): 100%|██████████| 10/10 [00:18<00:00,  1.87s/it]\n",
      "Training (39 / 1000 Steps) (loss=0.70103): 100%|██████████| 10/10 [00:22<00:00,  2.27s/it]\n",
      "Training (49 / 1000 Steps) (loss=0.64819): 100%|██████████| 10/10 [00:18<00:00,  1.85s/it]\n",
      "Training (59 / 1000 Steps) (loss=0.63909): 100%|██████████| 10/10 [00:18<00:00,  1.83s/it]\n",
      "Training (69 / 1000 Steps) (loss=0.63445): 100%|██████████| 10/10 [00:18<00:00,  1.87s/it]\n",
      "Training (79 / 1000 Steps) (loss=0.47958): 100%|██████████| 10/10 [00:18<00:00,  1.81s/it]\n",
      "Training (89 / 1000 Steps) (loss=0.49246): 100%|██████████| 10/10 [00:18<00:00,  1.89s/it]\n",
      "Training (99 / 1000 Steps) (loss=0.48077): 100%|██████████| 10/10 [00:17<00:00,  1.79s/it]\n",
      "Validate (100 / 10 Steps) (dice=0.94254): 100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.9392373144626618 Current Avg. Dice: 0.9392373144626618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (109 / 1000 Steps) (loss=0.56608): 100%|██████████| 10/10 [00:31<00:00,  3.13s/it]\n",
      "Training (119 / 1000 Steps) (loss=0.48768): 100%|██████████| 10/10 [00:19<00:00,  1.97s/it]\n",
      "Training (129 / 1000 Steps) (loss=0.45849): 100%|██████████| 10/10 [00:17<00:00,  1.78s/it]\n",
      "Training (139 / 1000 Steps) (loss=0.59224): 100%|██████████| 10/10 [00:18<00:00,  1.86s/it]\n",
      "Training (149 / 1000 Steps) (loss=0.42707): 100%|██████████| 10/10 [00:18<00:00,  1.90s/it]\n",
      "Training (159 / 1000 Steps) (loss=0.40931): 100%|██████████| 10/10 [00:17<00:00,  1.71s/it]\n",
      "Training (169 / 1000 Steps) (loss=0.41161): 100%|██████████| 10/10 [00:18<00:00,  1.81s/it]\n",
      "Training (179 / 1000 Steps) (loss=0.40412): 100%|██████████| 10/10 [00:19<00:00,  1.93s/it]\n",
      "Training (189 / 1000 Steps) (loss=0.35481): 100%|██████████| 10/10 [00:19<00:00,  1.93s/it]\n",
      "Training (199 / 1000 Steps) (loss=0.43654): 100%|██████████| 10/10 [00:18<00:00,  1.85s/it]\n",
      "Validate (200 / 10 Steps) (dice=0.94182): 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Not Saved ! Current Best Avg. Dice: 0.9392373144626618 Current Avg. Dice: 0.9372654438018799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (209 / 1000 Steps) (loss=0.43049): 100%|██████████| 10/10 [00:29<00:00,  2.95s/it]\n",
      "Training (219 / 1000 Steps) (loss=0.33585): 100%|██████████| 10/10 [00:17<00:00,  1.73s/it]\n",
      "Training (229 / 1000 Steps) (loss=0.42044): 100%|██████████| 10/10 [00:17<00:00,  1.77s/it]\n",
      "Training (239 / 1000 Steps) (loss=0.35464): 100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n",
      "Training (249 / 1000 Steps) (loss=0.56065): 100%|██████████| 10/10 [00:17<00:00,  1.77s/it]\n",
      "Training (259 / 1000 Steps) (loss=0.30176): 100%|██████████| 10/10 [00:19<00:00,  1.98s/it]\n",
      "Training (269 / 1000 Steps) (loss=0.28971): 100%|██████████| 10/10 [00:17<00:00,  1.78s/it]\n",
      "Training (279 / 1000 Steps) (loss=0.29634): 100%|██████████| 10/10 [00:18<00:00,  1.88s/it]\n",
      "Training (289 / 1000 Steps) (loss=0.25047): 100%|██████████| 10/10 [00:18<00:00,  1.88s/it]\n",
      "Training (299 / 1000 Steps) (loss=0.27577): 100%|██████████| 10/10 [00:18<00:00,  1.82s/it]\n",
      "Validate (300 / 10 Steps) (dice=0.94829): 100%|██████████| 10/10 [00:11<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Was Saved ! Current Best Avg. Dice: 0.943657511472702 Current Avg. Dice: 0.943657511472702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (309 / 1000 Steps) (loss=0.33832): 100%|██████████| 10/10 [00:32<00:00,  3.24s/it]\n",
      "Training (319 / 1000 Steps) (loss=0.28621): 100%|██████████| 10/10 [00:18<00:00,  1.80s/it]\n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    dice_vals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _step, batch in enumerate(epoch_iterator_val):\n",
    "            val_inputs, val_labels = (\n",
    "                batch[\"image\"], batch[\"label\"])\n",
    "            val_outputs = sliding_window_inference(\n",
    "                val_inputs, (32, 32, 32), 4, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(\n",
    "                val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor)\n",
    "                                  for val_pred_tensor in val_outputs_list]\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            dice = dice_metric.aggregate().item()\n",
    "            dice_vals.append(dice)\n",
    "            epoch_iterator_val.set_description(\n",
    "                \"Validate (%d / %d Steps) (dice=%2.5f)\" % (global_step, 10.0, dice))\n",
    "\n",
    "        dice_metric.reset()\n",
    "\n",
    "    mean_dice_val = np.mean(dice_vals)\n",
    "    return mean_dice_val\n",
    "\n",
    "\n",
    "def train(global_step, train_loader, dice_val_best, global_step_best):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(\n",
    "        train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True)\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        x, y = (batch[\"image\"], batch[\"label\"])\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iterator.set_description(\n",
    "            \"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss))\n",
    "\n",
    "        if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
    "            epoch_iterator_val = tqdm(\n",
    "                val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "            dice_val = validation(epoch_iterator_val)\n",
    "\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            metric_values.append(dice_val)\n",
    "            if dice_val > dice_val_best:\n",
    "                dice_val_best = dice_val\n",
    "                global_step_best = global_step\n",
    "                torch.save(model.state_dict(), os.path.join(\n",
    "                    logdir, \"best_metric_model_synth_1000.pth\"))\n",
    "                print(\n",
    "                    \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val)\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            plt.figure(1, (12, 6))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.title(\"Iteration Average Loss\")\n",
    "            x = [eval_num * (i + 1) for i in range(len(epoch_loss_values))]\n",
    "            y = epoch_loss_values\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.plot(x, y)\n",
    "            plt.grid()\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.title(\"Val Mean Dice\")\n",
    "            x = [eval_num * (i + 1) for i in range(len(metric_values))]\n",
    "            y = metric_values\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.plot(x, y)\n",
    "            plt.grid()\n",
    "            plt.savefig(os.path.join(logdir, \"btcv_finetune_quick_update_synth.png\"))\n",
    "            plt.clf()\n",
    "            plt.close(1)\n",
    "\n",
    "        global_step += 1\n",
    "    return global_step, dice_val_best, global_step_best\n",
    "\n",
    "\n",
    "while global_step < max_iterations:\n",
    "    global_step, dice_val_best, global_step_best = train(\n",
    "        global_step, train_loader, dice_val_best, global_step_best)\n",
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(logdir, \"best_metric_model_synth_1000.pth\")))\n",
    "\n",
    "print(\n",
    "    f\"train completed, best_metric: {dice_val_best:.4f} \" f\"at iteration: {global_step_best}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unetSSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
